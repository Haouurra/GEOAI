{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/geoaigroup/Aerial-SAM/blob/main/AerialSAM_GEOAI_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMt23BhFL5La"
      },
      "source": [
        "## SAM Online Demo: Segment everything Mode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4a4b25c"
      },
      "source": [
        "The Segment Anything Model (SAM) predicts object masks given prompts that indicate the desired object.\n",
        "\n",
        "Please go tho this link:\n",
        "https://segment-anything.com/demo\n",
        "\n",
        "And use this image as input:\n",
        "https://github.com/geoaigroup/Aerial-SAM/blob/main/483.png"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "644532a8"
      },
      "source": [
        "## Environment Set-up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07fabfee"
      },
      "source": [
        "If running locally using jupyter, first install `segment_anything` in your environment using the [installation instructions](https://github.com/facebookresearch/segment-anything#installation) in the repository. If running from Google Colab, set `using_colab=True` below and run the cell. In Colab, be sure to select 'GPU' under 'Edit'->'Notebook Settings'->'Hardware accelerator'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXi87ep3DNxC"
      },
      "outputs": [],
      "source": [
        "#Samples used in this demo are from the WHU Building Dataset: https://paperswithcode.com/dataset/whu-building-dataset\n",
        "!wget https://github.com/geoaigroup/Aerial-SAM/raw/main/resources/data.zip\n",
        "!wget https://github.com/geoaigroup/Aerial-SAM/raw/main/resources/pred_shapefile.zip\n",
        "!unzip data.zip\n",
        "!unzip pred_shapefile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ea65efc"
      },
      "outputs": [],
      "source": [
        "using_colab = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91dd9a89"
      },
      "outputs": [],
      "source": [
        "if using_colab:\n",
        "    import torch\n",
        "    import torchvision\n",
        "    print(\"PyTorch version:\", torch.__version__)\n",
        "    print(\"Torchvision version:\", torchvision.__version__)\n",
        "    print(\"CUDA is available:\", torch.cuda.is_available())\n",
        "    import sys\n",
        "    !{sys.executable} -m pip install opencv-python matplotlib\n",
        "    !{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything.git'\n",
        "\n",
        "    !wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n",
        "    !pip install geopandas\n",
        "    !pip install rasterio\n",
        "    !git clone https://github.com/geoaigroup/buildingsSAM.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69b28288"
      },
      "outputs": [],
      "source": [
        "#Necessary imports and helper functions for displaying points, boxes, and masks.\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import geopandas as gpd\n",
        "import os\n",
        "import json\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "import shapely.geometry as sg\n",
        "from shapely import affinity\n",
        "from shapely.geometry import Point, Polygon\n",
        "import random\n",
        "from PIL import Image, ImageDraw\n",
        "import rasterio\n",
        "from rasterio.features import geometry_mask\n",
        "#from metrics import DiceScore,IoUScore\n",
        "import pandas as pd\n",
        "import gc\n",
        "import shutil\n",
        "import fiona\n",
        "import json\n",
        "\n",
        "import utils\n",
        "from evaluate import cal_scores,matching_algorithm\n",
        "from pred_SAM import SAM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6yDAdyql7lf"
      },
      "outputs": [],
      "source": [
        "\n",
        "def cal_score(gt_tile, pred_tile):\n",
        "    matcher = matching_algorithm(gt_tile, pred_tile)\n",
        "    iou_list, f1_scores, tp_pred_indices, tp_gt_indices, fp_indices, fn_indices, mscores, precision, recall = matcher.matching()\n",
        "    tp_iou_list, avg_tp_iou = matcher.tp_iou(tp_pred_indices, tp_gt_indices)\n",
        "    score = {}\n",
        "    scores_b = []\n",
        "    score['iou_list'] = iou_list\n",
        "    score['f1_scores'] = f1_scores\n",
        "    score['tp_iou_list'] = tp_iou_list\n",
        "    score['fp_indices'] = fp_indices\n",
        "    score['fn_indices'] = fn_indices\n",
        "    score['Mean_iou'] = np.mean(iou_list, dtype=float)\n",
        "    score['Mean_f1'] = np.mean(f1_scores, dtype=float)\n",
        "    score['avg_tp_iou'] = float(avg_tp_iou) if avg_tp_iou != None else 0.0\n",
        "    score['precision'] = precision\n",
        "    score['recall'] = recall\n",
        "\n",
        "    for s in mscores:\n",
        "        scores_b.append(s)\n",
        "    scores_b.append(score)\n",
        "\n",
        "    gtmask=np.zeros((512,512))\n",
        "    predmask=np.zeros((512,512))\n",
        "    for g in gt_tile:\n",
        "        gtmask=g+gtmask\n",
        "    for p in pred_tile:\n",
        "        predmask=p+predmask\n",
        "    fig,ax = plt.subplots(1,2,figsize = (10,10))\n",
        "    ax = ax.ravel()\n",
        "    ax[0].imshow(gtmask)\n",
        "    ax[0].set_title(\"GT\")\n",
        "    ax[1].imshow(predmask)\n",
        "    ax[1].set_title(\"MultiClassUnet CNN\")\n",
        "    plt.show()\n",
        "\n",
        "    return scores_b\n",
        "\n",
        "def Calculate_CNN_Results():\n",
        "    ff = gpd.read_file(pred)\n",
        "    score_list = []\n",
        "\n",
        "    ids = [f for f in os.listdir(orig_shp)]\n",
        "\n",
        "    for name in tqdm(ids):\n",
        "        print(name)\n",
        "        if glob.glob(score_dir + \"/\" + name + \"_score.json\" ):\n",
        "            print(\"Found\")\n",
        "            continue\n",
        "        if name in os.listdir(orig_shp):\n",
        "            try:\n",
        "                gt = gpd.read_file(orig_shp + \"/\" + name)\n",
        "                if len(gt[\"geometry\"]) == 0:\n",
        "                    continue\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "                continue\n",
        "        else:\n",
        "            continue\n",
        "        predic = ff.loc[ff[\"ImageId\"] == name]\n",
        "        n=name.split('.')[0]\n",
        "        if len(predic[\"geometry\"]) == 0:\n",
        "            continue\n",
        "\n",
        "\n",
        "        gc.collect()\n",
        "\n",
        "        gt_tile = []\n",
        "        pred_tile=[]\n",
        "\n",
        "        gt_tile=utils.convert_polygon_to_mask_batch(gt['geometry'])\n",
        "        pred_tile=utils.convert_polygon_to_mask_batch(predic[\"geometry\"])\n",
        "\n",
        "        scores_res=cal_score(gt_tile, pred_tile)\n",
        "        os.makedirs(score_dir, exist_ok=True)\n",
        "\n",
        "        with open(score_dir + f'/{name}_score.json', 'w') as f1:\n",
        "            json.dump(scores_res, f1)\n",
        "\n",
        "    scores=cal_scores(output_dir,score_dir)\n",
        "    scores.macro_score()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTMYJz817o2c"
      },
      "outputs": [],
      "source": [
        "def main(CNN=\"\",prompt_type=\"\",sam=None):\n",
        "    score_list = []\n",
        "    scores=cal_scores(output_dir,score_dir)\n",
        "    # ff = gpd.read_file(pred)\n",
        "    ids = [f for f in os.listdir(orig_shp)]\n",
        "    for name in tqdm(ids):\n",
        "        print(name)\n",
        "        print(\"Checking\")\n",
        "        flag=0\n",
        "        if glob.glob(output_dir + \"/\" + name + \"/\" + name + \".shp\" ) or glob.glob(output_dir + \"/\" + name + \"/\" + name + \".png\" ):\n",
        "            print(\"Found\")\n",
        "            continue\n",
        "\n",
        "        tile_boxes = []\n",
        "        try:\n",
        "            image = cv2.imread(images + \"/\" + name+'.png')\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            print(name)\n",
        "\n",
        "        if name in os.listdir(orig_shp):\n",
        "                gt = gpd.read_file(orig_shp + \"/\" + name)\n",
        "                if len(gt[\"geometry\"]) == 0:\n",
        "                    continue\n",
        "        else:\n",
        "            continue\n",
        "        if CNN==\"multiclassUnet\":\n",
        "\n",
        "            predic = ff.loc[ff[\"ImageId\"] == name]\n",
        "\n",
        "        elif CNN==\"DCNN\":\n",
        "            predic = gpd.read_file(pred+\"/\"+name)\n",
        "\n",
        "        geo = predic[\"geometry\"]\n",
        "\n",
        "        if len(geo) == 0:\n",
        "            continue\n",
        "\n",
        "        input_point=None\n",
        "        input_label=None\n",
        "        input_boxes=None\n",
        "         \n",
        "        match prompt_type:\n",
        "            case \"single point\":\n",
        "                input_point,input_label=utils.create_list_points(geo,name)\n",
        "            case \"single + negative points\":\n",
        "                input_point,input_label=utils.create_list_points(geo,name,flag=\"negative\")\n",
        "                print(input_point)\n",
        "                print(input_label)\n",
        "            #Skeleton\n",
        "            case \"skeleton\":\n",
        "                input_point=[]\n",
        "                input_label=[]\n",
        "                with open(skeleton_points, 'r') as json_file:\n",
        "                    data = json.load(json_file)\n",
        "                matching_items = []\n",
        "                for item in data:\n",
        "                    if item['id'] == name:\n",
        "                        matching_items.append(item)\n",
        "\n",
        "                input_point=torch.Tensor(matching_items[0]['input_points']).cuda()\n",
        "                input_label=torch.Tensor(matching_items[0]['input_labels']).cuda().long()\n",
        "\n",
        "            case \"multiple points\":\n",
        "                input_point,input_label=utils.generate_random_points_polygon(geo)\n",
        "            \n",
        "            case \"multiple points + single point\":\n",
        "                input_point,input_label=utils.generate_random_points_polygon(geo,flag=\"rep\")\n",
        "\n",
        "            case \"multiple points + negative points\":\n",
        "                input_point,input_label=utils.generate_random_points_polygon(geo,flag=\"negative\")\n",
        "           \n",
        "            #creating boxes\n",
        "            case \"box\":\n",
        "                input_boxes=[]\n",
        "                flag=1\n",
        "                tile_boxes=utils.create_boxes(geo)\n",
        "                input_boxes=torch.tensor(tile_boxes).cuda()\n",
        "            \n",
        "            case \"box + single point\":\n",
        "                input_boxes=[]   \n",
        "                tile_boxes=utils.create_boxes(geo)\n",
        "                input_boxes=torch.tensor(tile_boxes).cuda()\n",
        "                input_point,input_label=utils.create_list_points(geo,name)\n",
        "\n",
        "            case \"box + multiple points\":\n",
        "                input_boxes=[]\n",
        "                tile_boxes=utils.create_boxes(geo)\n",
        "                input_boxes=torch.tensor(tile_boxes).cuda()\n",
        "                input_point,input_label=utils.generate_random_points_polygon(geo)\n",
        "\n",
        "            case _:\n",
        "                print(\"no or wrong prompt entered\")\n",
        "\n",
        "        x = torch.from_numpy(image.transpose(2, 0, 1)).float().cuda()\n",
        "        pred_mask=sam.predictSAM(x=x,image=image,input_point=input_point,input_label=input_label,input_boxes=input_boxes,flag=flag)\n",
        "        os.makedirs(score_dir, exist_ok=True)\n",
        "        os.makedirs(output_dir + \"/\" + f\"{name}\", exist_ok=True)\n",
        "\n",
        "        scores.micro_match_iou(pred_mask,name,gt,score_list,image,input_point,input_label,tile_boxes,geo=geo)\n",
        "    scores.macro_score()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0BR_5fc6N9S7"
      },
      "outputs": [],
      "source": [
        "# Paths\n",
        "checkpoint=\"data/checkpoint/sam_vit_h_4b8939.pth\"\n",
        "images = \"data/images\"\n",
        "orig_shp=\"data/orig_shp\"\n",
        "skeleton_points=\"data/points.json\"\n",
        "pred = \"data/pred_shapefile\"\n",
        "output_dir = \"data/MulticlassUdfnet_0-0=s_output\"\n",
        "score_dir = \"data/MulticlassUndfet_00-oi0nts_scores\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0hmealy7o2d"
      },
      "outputs": [],
      "source": [
        "#get Multiclass Unet initial results\n",
        "# Calculate_CNN_Results()\n",
        "\n",
        "#loading SAM Model\n",
        "sam=SAM(checkpoint)\n",
        "\n",
        "#load Multiclass Unet CNN prediction file\n",
        "ff = gpd.read_file(pred)\n",
        "\n",
        "#Run SAM prediction with box prompt\n",
        "main(CNN=\"multiclassUnet\",prompt_type=\"box\",sam=sam)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7X3LU3_oN9S8"
      },
      "outputs": [],
      "source": [
        "#for D-linkNet model\n",
        "pred = \"data/DCNN_pred_shapefile\"\n",
        "sam=SAM(checkpoint)\n",
        "main(CNN=\"DCNN\",prompt_type=\"box\",sam=sam)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oow_J4wm_qBk"
      },
      "source": [
        "LangSAM : https://github.com/luca-medeiros/lang-segment-anything\n",
        "\n",
        "GroundingDINO: https://github.com/IDEA-Research/GroundingDINO\n",
        "\n",
        "Segment Anything : https://github.com/facebookresearch/segment-anything\n",
        "\n",
        "**Language Segment-Anything (LangSAM)** is an open-source project that combines the power of instance segmentation and text prompts to generate masks for specific objects in images. Built on the recently released Meta model, segment-anything, and the GroundingDINO detection model, it's an easy-to-use and effective tool for object detection and image segmentation.\n",
        "\n",
        "This section was prepared by Hasan Moughnieh."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyCDYhkDEWCO"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/geoaigroup/Aerial-SAM/raw/main/resources/LangSAM_samples.zip\n",
        "!wget https://github.com/geoaigroup/Aerial-SAM/raw/main/resources/LangSAM_scripts.zip\n",
        "!unzip LangSAM_samples.zip\n",
        "!unzip LangSAM_scripts.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAtDoF_-_4uR"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install opencv-python matplotlib\n",
        "!{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything.git'\n",
        "!pip install git+https://github.com/openai/CLIP.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Bia-pl5_61v"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0rYB8y40_8dh"
      },
      "outputs": [],
      "source": [
        "%cd {HOME}\n",
        "!git clone https://github.com/IDEA-Research/GroundingDINO.git\n",
        "%cd {HOME}/GroundingDINO\n",
        "!pip install -q -e .\n",
        "!pip install -q roboflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zrstnu_fARcY"
      },
      "source": [
        "\n",
        "Grounding DINO:\n",
        "\n",
        "Image + Text --> 900 bounding boxes(by default) each with similarity score with respect to the input words\n",
        "\n",
        "900 boxes --> filtered according to the box_threshold (similarity score > box_threshold)\n",
        "\n",
        "extract the words whose similarities are higher than the text_threshold as predicted labels.\n",
        "\n",
        "The optimal threshold can vary depending on the quality and nature of your images, as well as the specificity of your text prompts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2e5pW-SAPHD"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from LangSAM import LangSAM\n",
        "from demo_functions import load_ground_truth_masks , display_images_with_masks\n",
        "\n",
        "index = '2_36'\n",
        "#replace 2_37 or 2_102 for more good samples\n",
        "# replace with 0 or 2_87 for some bad results\n",
        "# or upload an image of your own\n",
        "image = f'/content/{index}_img.png'\n",
        "ground_truth_mask = f'/content/{index}_gt.png'\n",
        "\n",
        "model = LangSAM()\n",
        "\n",
        "image_pil = Image.open(image).convert(\"RGB\")\n",
        "text_prompt = \"house\" #here you can change your textual input(query)\n",
        "masks, boxes, phrases, logits = model.predict(image_pil, text_prompt)\n",
        "ground_truth_masks = load_ground_truth_masks(ground_truth_mask)\n",
        "\n",
        "#This function displays the original image , predicted masks , and accuracy compared to ground truth\n",
        "display_images_with_masks(image_pil, masks , boxes, ground_truth_mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSPcAiI13Kix"
      },
      "source": [
        "Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JmG9O1WM_Jaz"
      },
      "outputs": [],
      "source": [
        "from demo_functions import MaskMatchingAlgorithm\n",
        "\n",
        "matcher = MaskMatchingAlgorithm(ground_truth_mask, masks)\n",
        "output = matcher.matching()\n",
        "iou_list = output[0]\n",
        "tp_pred_indices = output[1]\n",
        "tp_gt_indices = output[2]\n",
        "fp_indices = output[3]\n",
        "fn_indices = output[4]\n",
        "tp_iou_list, avg_tp_iou = matcher.tp_iou(tp_pred_indices, tp_gt_indices)\n",
        "average_iou, avg_tp_iou , precision , recall , f1_score, tp_f1 = matcher.display_results(iou_list ,tp_pred_indices,\n",
        "                                                                                                tp_gt_indices,\n",
        "                                                                                                fp_indices,\n",
        "                                                                                                fn_indices ,\n",
        "                                                                                                tp_iou_list,\n",
        "                                                                                                avg_tp_iou)\n",
        "print(\" F1 score\" , tp_f1)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
