# Aerial SAM  

[![Conference](https://img.shields.io/badge/ECRS-Conference-brightgreen)](https://ecrs2023.sciforum.net/)
[![Workshop](https://img.shields.io/badge/NOAA%20Workshop-5th%20AI%20Demo-blue)](https://noaaai2023.sched.com/)

Welcome to the official repository for our paper titled "Zero-Shot Refinement of Buildingsâ€™ Segmentation Models using SAM" to appear at the 5th International Electronic Conference on Remote Sensing (ECRS 2023).

## Overview

Our research focuses on  a zero-shot refinement approach where the inference results of a CNN trained for buildings' segmentation from remote sensing images are passed as input to SAM. This repository contains the code and resources used to produce the results presented in our paper. Also, this repo hosts materail for our live demo entitled "Zero-Shot Buildings' Segmentation using SAM" at the 5th NOAA Workshop on Leveraging AI in Environmental Sciences.

## Key Features

- Implementation of state-of-the-art AI models for building segmentation in remote sensing.
  - *Coming Soon!* Our state-of-the-art AI models for building segmentation will be released upon paper acceptance. Stay tuned!
  
- Reproducible code for generating the results discussed in our paper.
  - *Coming Soon!* Our reproducible code will be made available once our paper is submitted. Anticipate the release!

- A comprehensive Colab notebook for a live demo presented at the 5th NOAA Workshop.
  - This notebook contains an implementation of vanilla [SAM](https://github.com/facebookresearch/segment-anything) on remote sensing data.
  - It also includes the use of [LangSAM](https://github.com/luca-medeiros/lang-segment-anything), an innovative integration of two powerful models: the foundation model [SAM](https://github.com/facebookresearch/segment-anything) and the visual grounding model [Grounding Dino]( https://github.com/IDEA-Research/GroundingDINO). This combination enables the use of textual prompts with SAM on remote sensing data.

