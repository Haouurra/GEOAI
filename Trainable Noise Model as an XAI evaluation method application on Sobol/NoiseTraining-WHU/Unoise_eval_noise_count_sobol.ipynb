{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4927cd7-22dc-4e00-a860-be76019e7ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "image_indexx = torch.arange(10)\n",
    "# image_indexx = [2]\n",
    "# print(image_indexx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a977cef4-55db-4860-bb94-594d82c613aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import cv2\n",
    "from glob import glob\n",
    "import os\n",
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch.encoders import get_preprocessing_fn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from dataset_cityscapes import *\n",
    "from epoch import *\n",
    "import neptune\n",
    "import pickle\n",
    "from segmentation_models_pytorch import Unet\n",
    "import torch\n",
    "import argparse\n",
    "import os\n",
    "import cv2\n",
    "from segmentation_models_pytorch import Unet\n",
    "from skimage.io import imread,imsave\n",
    "import numpy as np\n",
    "import rasterio as rio\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "\n",
    "from utils import *\n",
    "# from color_map import cm_data\n",
    "from rasterio.features import shapes\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def to_tensor(x, **kwargs):\n",
    "    return x.transpose(2, 0, 1).astype(\"float32\")\n",
    "\n",
    "\n",
    "# ======== CONFIGURATION ======== #\n",
    "S_NAME_ENCODER = \"efficientnet-b4\"\n",
    "S_NAME_WEIGHTS = \"imagenet\"\n",
    "P_DIR_MODEL_NOISE = \"/home/jamada/jupyterlab/eo-xai/whu_noise_training/UNET_EfficientNetB4_CE/Checkpoints-479/model_epoch_0050.pth\"\n",
    "\n",
    "# S_DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"CPU\")\n",
    "S_DEVICE = 'cpu'\n",
    "P_DIR_MODEL_UTIL =\"/home/jamada/UrbanModels/weights_pytorch/tu-tf_efficientnet_b0_Unet_whu_3-classes_40-epochs_TRY001\"\n",
    "\n",
    "# ======== UTILITY ======== #\n",
    "model = Unet(\n",
    "        encoder_name = \"tu-tf_efficientnet_b0\",\n",
    "        encoder_depth= 5,\n",
    "        encoder_weights = None,\n",
    "        decoder_use_batchnorm = True,\n",
    "        decoder_channels = (256, 128, 64, 32, 16),\n",
    "        decoder_attention_type = None,\n",
    "        in_channels= 3,\n",
    "        classes = 3,\n",
    "        activation = 'sigmoid',\n",
    "        aux_params = None,\n",
    "    )\n",
    "\n",
    "utility_model = load_model(model,P_DIR_MODEL_UTIL)\n",
    "\n",
    "# ======== SETUP ======== #\n",
    "# setup model\n",
    "noise_model = torch.load(P_DIR_MODEL_NOISE, map_location=S_DEVICE)  \n",
    "noise_model.eval()\n",
    "\n",
    "# setup input normalization\n",
    "preprocess_input = get_preprocessing_fn(\n",
    "    encoder_name = S_NAME_ENCODER,\n",
    "    pretrained = S_NAME_WEIGHTS,\n",
    ")\n",
    "\n",
    "transform_full = A.Compose([\n",
    "    A.Lambda(name = \"to_tensor\", image = to_tensor),\n",
    "])\n",
    "\n",
    "# setup datasets\n",
    "dataset_test = DataLoaderSegmentation(\n",
    "    image_path = \"/home/jamada/jupyterlab/datasets/WHU/WHU_building/train/A\",\n",
    "    mask_path = \"/home/jamada/jupyterlab/datasets/WHU/WHU_building/train/OUT\",\n",
    "    transform = transform_full,\n",
    "    device = S_DEVICE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57a989e-9dea-4670-ba44-e20288157c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Saturday, August 20, 2022\n",
    "Updated on Wednesday, June, 14, 2023\n",
    "@author: Abdul Karim GIZZINI\n",
    "\"\"\"\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import ttach as tta\n",
    "import torch\n",
    "import warnings\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "from segmentation_models_pytorch import Unet\n",
    "import argparse\n",
    "import os\n",
    "from typing import Callable, List\n",
    "import cv2\n",
    "import tqdm\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image, preprocess_image\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.measure import label\n",
    "from pytorch_grad_cam.utils.svd_on_activations import get_2d_projection\n",
    "from pytorch_grad_cam.utils.image import scale_cam_image\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "\n",
    "# Grad-Cam Classes\n",
    "class ActivationsAndGradients:\n",
    "    \"\"\" Class for extracting activations and\n",
    "    registering gradients from targetted intermediate layers \"\"\"\n",
    "\n",
    "    def __init__(self, model, target_layers, reshape_transform):\n",
    "        self.model = model\n",
    "        self.gradients = []\n",
    "        self.activations = []\n",
    "        self.reshape_transform = reshape_transform\n",
    "        self.handles = []\n",
    "        for target_layer in target_layers:\n",
    "            self.handles.append(\n",
    "                target_layer.register_forward_hook(self.save_activation))\n",
    "            # Because of https://github.com/pytorch/pytorch/issues/61519,\n",
    "            # we don't use backward hook to record gradients.\n",
    "            self.handles.append(\n",
    "                target_layer.register_forward_hook(self.save_gradient))\n",
    "\n",
    "    def save_activation(self, module, input, output):\n",
    "        activation = output\n",
    "        if self.reshape_transform is not None:\n",
    "            activation = self.reshape_transform(activation)\n",
    "        self.activations.append(activation.cpu().detach())\n",
    "\n",
    "    def save_gradient(self, module, input, output):\n",
    "        if not hasattr(output, \"requires_grad\") or not output.requires_grad:\n",
    "            # You can only register hooks on tensor requires grad.\n",
    "            return\n",
    "\n",
    "        # Gradients are computed in reverse order\n",
    "        def _store_grad(grad):\n",
    "            if self.reshape_transform is not None:\n",
    "                grad = self.reshape_transform(grad)\n",
    "            self.gradients = [grad.cpu().detach()] + self.gradients\n",
    "            # self.gradients = [torch.mul(t, -1) for t in self.gradients]\n",
    "\n",
    "        output.register_hook(_store_grad)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        self.gradients = []\n",
    "        self.activations = []\n",
    "        return self.model(x)\n",
    "\n",
    "    def release(self):\n",
    "        for handle in self.handles:\n",
    "            handle.remove()\n",
    "\n",
    "\n",
    "class GRADCAMEXTENDED:\n",
    "    def __init__(self, model: torch.nn.Module, target_layers: List[torch.nn.Module], use_cuda: bool = False,\n",
    "                 reshape_transform: Callable = None, compute_input_gradient: bool = False,\n",
    "                 uses_gradients: bool = True) -> None:\n",
    "        self.model = model.eval()\n",
    "        self.target_layers = target_layers\n",
    "        self.cuda = use_cuda\n",
    "        if self.cuda:\n",
    "            self.model = model.cuda()\n",
    "        self.reshape_transform = reshape_transform\n",
    "        self.compute_input_gradient = compute_input_gradient\n",
    "        self.uses_gradients = uses_gradients\n",
    "        self.activations_and_grads = ActivationsAndGradients(self.model, target_layers, reshape_transform)\n",
    "\n",
    "    def forward(self, input_tensor: torch.Tensor, targets: List[torch.nn.Module],\n",
    "                eigen_smooth: bool = False) -> np.ndarray:\n",
    "\n",
    "        # print('\\n----------------------------------------Seg-Grad-Cam----------------------------------------------------\\n')\n",
    "\n",
    "        if self.cuda:\n",
    "            input_tensor = input_tensor.cuda()\n",
    "        if self.compute_input_gradient:\n",
    "            input_tensor = torch.autograd.Variable(input_tensor, requires_grad=True)\n",
    "\n",
    "        outputs = self.activations_and_grads(input_tensor)\n",
    "        if targets is None:\n",
    "            target_categories = np.argmax(outputs.cpu().data.numpy(), axis=-1)\n",
    "            targets = [ClassifierOutputTarget(category) for category in target_categories]\n",
    "\n",
    "        if self.uses_gradients:\n",
    "            self.model.zero_grad()\n",
    "            loss = sum([target(output) for target, output in zip(targets, outputs)])\n",
    "            loss.backward(retain_graph=True)\n",
    "\n",
    "        activations_list = [a.cpu().data.numpy() for a in self.activations_and_grads.activations]\n",
    "        grads_list = [g.cpu().data.numpy() for g in self.activations_and_grads.gradients]\n",
    "        target_size = input_tensor.size(-1), input_tensor.size(-2)\n",
    "        # print('Activations list size: ', len(activations_list))\n",
    "        # print('Gradients list size: ', len(grads_list))\n",
    "        # print('Target layer size: ', len(self.target_layers))\n",
    "\n",
    "        cam_per_target_layer = []\n",
    "        # Loop over the saliency image from every layer\n",
    "        for i in range(len(self.target_layers)):\n",
    "            target_layer = self.target_layers[i]\n",
    "            # print('\\t\\t\\t-----------------------\\n')\n",
    "            # print('Target Layer ', i + 1, ': ', target_layer)\n",
    "            layer_activations = None\n",
    "            layer_grads = None\n",
    "            if i < len(activations_list):\n",
    "                layer_activations = activations_list[i]\n",
    "            if i < len(grads_list):\n",
    "                layer_grads = grads_list[i]\n",
    "\n",
    "            # layer_grads = - layer_grads\n",
    "            weights = np.mean(layer_grads, axis=(2, 3))\n",
    "            weighs_up = weights[:, :, None, None] \n",
    "            # print('weights updated: ', weighs_up.shape)\n",
    "            weighted_activations = weights[:, :, None, None] * layer_activations\n",
    "            # print('Activations per layer size: ', layer_activations.shape)\n",
    "            # print('Gradients per layer size: ', layer_grads.shape)\n",
    "            # print('Weights per layer size: ', weights.shape)\n",
    "            # print(\"Weights  x activation: \", weighted_activations.shape)\n",
    "            if eigen_smooth:\n",
    "                cam = get_2d_projection(weighted_activations)\n",
    "                print(\"Cam image per layer size: \", cam.shape)\n",
    "            else:\n",
    "                cam = weighted_activations.sum(axis=1)\n",
    "                # print(\"Cam image per layer size: \", cam.shape)\n",
    "\n",
    "            cam = np.maximum(cam, 0)\n",
    "            # print(\"Cam image  Max per layer size: \", cam.shape)\n",
    "            scaled = scale_cam_image(cam, target_size)\n",
    "            # print(\"Scaled Cam image per layer size: \", scaled.shape)\n",
    "            cam_per_target_layer.append(scaled[:, None, :])\n",
    "\n",
    "        # print(\"Cam image list size: \", len(cam_per_target_layer))\n",
    "        cam_per_target_layer = np.concatenate(cam_per_target_layer, axis=1)\n",
    "        # print(\"Cam image list Concat size: \", len(cam_per_target_layer))\n",
    "        cam_per_target_layer = np.maximum(cam_per_target_layer, 0)\n",
    "        # print(\"Cam image list (max) size: \", len(cam_per_target_layer))\n",
    "        result = np.mean(cam_per_target_layer, axis=1)\n",
    "        # print(\"+++ Averaged CAM list size: \", result.shape)\n",
    "\n",
    "        \n",
    "        return scale_cam_image(result) # result\n",
    "\n",
    "    def __call__(self, input_tensor: torch.Tensor, targets: List[torch.nn.Module] = None, aug_smooth: bool = False,\n",
    "                 eigen_smooth: bool = False) -> np.ndarray:\n",
    "        # Smooth the CAM result with test time augmentation\n",
    "        if aug_smooth is True:\n",
    "            transforms = tta.Compose(\n",
    "                [\n",
    "                    tta.HorizontalFlip(),\n",
    "                    tta.Multiply(factors=[0.9, 1, 1.1]),\n",
    "                ]\n",
    "            )\n",
    "            cams = []\n",
    "            for transform in transforms:\n",
    "                augmented_tensor = transform.augment_image(input_tensor)\n",
    "                cam = self.forward(augmented_tensor, targets, eigen_smooth)\n",
    "                # The ttach library expects a tensor of size BxCxHxW\n",
    "                cam = cam[:, None, :, :]\n",
    "                cam = torch.from_numpy(cam)\n",
    "                cam = transform.deaugment_mask(cam)\n",
    "                # Back to numpy float32, HxW\n",
    "                cam = cam.numpy()\n",
    "                cam = cam[:, 0, :, :]\n",
    "                cams.append(cam)\n",
    "            cam = np.mean(np.float32(cams), axis=0)\n",
    "            return cam\n",
    "        else:\n",
    "            return self.forward(input_tensor, targets, eigen_smooth)\n",
    "\n",
    "    def __del__(self):\n",
    "        self.activations_and_grads.release()\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, exc_tb):\n",
    "        self.activations_and_grads.release()\n",
    "        if isinstance(exc_value, IndexError):\n",
    "            # Handle IndexError here...\n",
    "            print(\n",
    "                f\"An exception occurred in CAM with block: {exc_type}. Message: {exc_value}\")\n",
    "            return True\n",
    "\n",
    "\n",
    "\n",
    "class GRADCAMEXTENDED_Plusplus:\n",
    "    def __init__(self, model: torch.nn.Module, target_layers: List[torch.nn.Module], use_cuda: bool = False,\n",
    "                 reshape_transform: Callable = None, compute_input_gradient: bool = False,\n",
    "                 uses_gradients: bool = True) -> None:\n",
    "        self.model = model.eval()\n",
    "        self.target_layers = target_layers\n",
    "        self.cuda = use_cuda\n",
    "        if self.cuda:\n",
    "            self.model = model.cuda()\n",
    "        self.reshape_transform = reshape_transform\n",
    "        self.compute_input_gradient = compute_input_gradient\n",
    "        self.uses_gradients = uses_gradients\n",
    "        self.activations_and_grads = ActivationsAndGradients(self.model, target_layers, reshape_transform)\n",
    "\n",
    "    def forward(self, input_tensor: torch.Tensor, targets: List[torch.nn.Module],\n",
    "                eigen_smooth: bool = False) -> np.ndarray:\n",
    "\n",
    "        # print(\n",
    "        #     '\\n----------------------------------------Seg-Grad-Cam ++ ----------------------------------------------------\\n')\n",
    "\n",
    "        if self.cuda:\n",
    "            input_tensor = input_tensor.cuda()\n",
    "        if self.compute_input_gradient:\n",
    "            input_tensor = torch.autograd.Variable(input_tensor, requires_grad=True)\n",
    "\n",
    "        outputs = self.activations_and_grads(input_tensor)\n",
    "        if targets is None:\n",
    "            target_categories = np.argmax(outputs.cpu().data.numpy(), axis=-1)\n",
    "            targets = [ClassifierOutputTarget(category) for category in target_categories]\n",
    "\n",
    "        if self.uses_gradients:\n",
    "            self.model.zero_grad()\n",
    "            loss = sum([target(output) for target, output in zip(targets, outputs)])\n",
    "            loss.backward(retain_graph=True)\n",
    "\n",
    "        activations_list = [a.cpu().data.numpy() for a in self.activations_and_grads.activations]\n",
    "        grads_list = [g.cpu().data.numpy() for g in self.activations_and_grads.gradients]\n",
    "        target_size = input_tensor.size(-1), input_tensor.size(-2)\n",
    "        # print('Activations list size: ', len(activations_list))\n",
    "        # print('Gradients list size: ', len(grads_list))\n",
    "        # print('Target layer size: ', len(self.target_layers))\n",
    "\n",
    "        cam_per_target_layer = []\n",
    "        # Loop over the saliency image from every layer\n",
    "        for i in range(len(self.target_layers)):\n",
    "            target_layer = self.target_layers[i]\n",
    "            # print('\\t\\t\\t-----------------------\\n')\n",
    "            # print('Target Layer ', i + 1, ': ', target_layer)\n",
    "            layer_activations = None\n",
    "            layer_grads = None\n",
    "            if i < len(activations_list):\n",
    "                layer_activations = activations_list[i]\n",
    "            if i < len(grads_list):\n",
    "                layer_grads = grads_list[i]\n",
    "\n",
    "\n",
    "            grads_power_2 = layer_grads**2\n",
    "            grads_power_3 = grads_power_2 * layer_grads\n",
    "            # Equation 19 in https://arxiv.org/abs/1710.11063\n",
    "            sum_activations = np.sum(layer_activations, axis=(2, 3))\n",
    "            eps = 0.000001\n",
    "            aij = grads_power_2 / (2 * grads_power_2 +\n",
    "                               sum_activations[:, :, None, None] * grads_power_3 + eps)\n",
    "            # Now bring back the ReLU from eq.7 in the paper,\n",
    "            # And zero out aijs where the activations are 0\n",
    "            aij = np.where(layer_grads != 0, aij, 0)\n",
    "\n",
    "            weights = np.maximum(layer_grads, 0) * aij\n",
    "            weights = np.sum(weights, axis=(2, 3))\n",
    "            # print('weights updated: ', weighs_up.shape)\n",
    "            weighted_activations = weights[:, :, None, None] * layer_activations\n",
    "            # print('Activations per layer size: ', layer_activations.shape)\n",
    "            # print('Gradients per layer size: ', layer_grads.shape)\n",
    "            # print('Weights per layer size: ', weights.shape)\n",
    "            # print(\"Weights  x activation: \", weighted_activations.shape)\n",
    "            if eigen_smooth:\n",
    "                cam = get_2d_projection(weighted_activations)\n",
    "                print(\"Cam image per layer size: \", cam.shape)\n",
    "            else:\n",
    "                cam = weighted_activations.sum(axis=1)\n",
    "                # print(\"Cam image per layer size: \", cam.shape)\n",
    "\n",
    "            cam = np.maximum(cam, 0)\n",
    "            # print(\"Cam image  Max per layer size: \", cam.shape)\n",
    "            scaled = scale_cam_image(cam, target_size)\n",
    "            # print(\"Scaled Cam image per layer size: \", scaled.shape)\n",
    "            cam_per_target_layer.append(scaled[:, None, :])\n",
    "\n",
    "        # print(\"Cam image list size: \", len(cam_per_target_layer))\n",
    "        cam_per_target_layer = np.concatenate(cam_per_target_layer, axis=1)\n",
    "        # print(\"Cam image list Concat size: \", len(cam_per_target_layer))\n",
    "        cam_per_target_layer = np.maximum(cam_per_target_layer, 0)\n",
    "        # print(\"Cam image list (max) size: \", len(cam_per_target_layer))\n",
    "        result = np.mean(cam_per_target_layer, axis=1)\n",
    "        # print(\"+++ Averaged CAM list size: \", result.shape)\n",
    "\n",
    "        \n",
    "        return scale_cam_image(result) # result\n",
    "\n",
    "    def __call__(self, input_tensor: torch.Tensor, targets: List[torch.nn.Module] = None, aug_smooth: bool = False,\n",
    "                 eigen_smooth: bool = False) -> np.ndarray:\n",
    "        # Smooth the CAM result with test time augmentation\n",
    "        if aug_smooth is True:\n",
    "            transforms = tta.Compose(\n",
    "                [\n",
    "                    tta.HorizontalFlip(),\n",
    "                    tta.Multiply(factors=[0.9, 1, 1.1]),\n",
    "                ]\n",
    "            )\n",
    "            cams = []\n",
    "            for transform in transforms:\n",
    "                augmented_tensor = transform.augment_image(input_tensor)\n",
    "                cam = self.forward(augmented_tensor, targets, eigen_smooth)\n",
    "                # The ttach library expects a tensor of size BxCxHxW\n",
    "                cam = cam[:, None, :, :]\n",
    "                cam = torch.from_numpy(cam)\n",
    "                cam = transform.deaugment_mask(cam)\n",
    "                # Back to numpy float32, HxW\n",
    "                cam = cam.numpy()\n",
    "                cam = cam[:, 0, :, :]\n",
    "                cams.append(cam)\n",
    "            cam = np.mean(np.float32(cams), axis=0)\n",
    "            return cam\n",
    "        else:\n",
    "            return self.forward(input_tensor, targets, eigen_smooth)\n",
    "\n",
    "    def __del__(self):\n",
    "        self.activations_and_grads.release()\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, exc_tb):\n",
    "        self.activations_and_grads.release()\n",
    "        if isinstance(exc_value, IndexError):\n",
    "            # Handle IndexError here...\n",
    "            print(\n",
    "                f\"An exception occurred in CAM with block: {exc_type}. Message: {exc_value}\")\n",
    "            return True\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142e9239-077f-474a-8087-1c60011e5c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "###load the lists\n",
    "list_of_images = torch.load('./list_of_images.t')\n",
    "list_of_masks = torch.load('./list_of_masks.t')\n",
    "list_of_sobol = torch.load('./list_of_sobol.t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662e57aa-d4c1-4513-9422-1172c56aaabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "###check the loaded lists\n",
    "# plt.imshow(list_of_sobol[0])\n",
    "# plt.show()\n",
    "print(list_of_sobol[0].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5c9455-c024-4fe3-b9b2-3e226de3a8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "YOU SHOULD UNCOMMNET DOWN IN THIS CELL THE INTEGRATION METHOD YOU WANT TO USE\n",
    "\n",
    "'''\n",
    "\n",
    "idxs = image_indexx\n",
    "n_imgs = len(idxs)\n",
    "# SEG-GRAD-CAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from scipy.special import softmax\n",
    "\n",
    "class SemanticSegmentationTarget:\n",
    "    def __init__(self, category, mask):\n",
    "        self.category = category\n",
    "        self.mask = torch.from_numpy(mask)\n",
    "        if torch.cuda.is_available():\n",
    "            self.mask = self.mask # .cuda()\n",
    "        \n",
    "    def __call__(self, model_output):\n",
    "        # print('Model Output: ', model_output.shape)\n",
    "        return (model_output[self.category, :, : ] * self.mask).sum()\n",
    "\n",
    "\n",
    "\n",
    "def deprocess_image(img):\n",
    "    \"\"\" see https://github.com/jacobgil/keras-grad-cam/blob/master/grad-cam.py#L65 \"\"\"\n",
    "    img = img - np.mean(img)\n",
    "    img = img / (np.std(img) + 1e-5)\n",
    "    img = img * 0.1\n",
    "    img = img + 0.5\n",
    "    img = np.clip(img, 0, 1)\n",
    "    return np.uint8(img * 255)\n",
    "\n",
    "\n",
    "def defaultScales():\n",
    "    classes_cmap = plt.get_cmap('Spectral', 20)\n",
    "    scale_fig = 2\n",
    "    fonts = 15\n",
    "    scatter_size = 330 * scale_fig\n",
    "    return classes_cmap, scale_fig, fonts, scatter_size\n",
    "\n",
    "# ticks = np.linspace(0, 1, 6, endpoint=True)\n",
    "\n",
    "# classes_cmap, scale_fig, fonts, scatter_size = defaultScales()\n",
    "\n",
    "# plt.figure(figsize=(15 * scale_fig, 10 * scale_fig))\n",
    "\n",
    "\n",
    "\n",
    "target_class = 'road'\n",
    "classid = 0 # road: 7, \n",
    "building_category = 0\n",
    "target_layers =  [model.decoder.blocks[0]]\n",
    "target_layers_all = [model.decoder.blocks[0], model.decoder.blocks[1] , model.decoder.blocks[2], model.decoder.blocks[3], model.decoder.blocks[4]]\n",
    "\n",
    "print('XAI Methods for Target Class: ', target_class, \"... \\n\\n\")\n",
    "\n",
    "number_testing_images = 0\n",
    "sobol_list=[]\n",
    "seg_pp_list=[]\n",
    "CAM_direct_output=[]\n",
    "CAMpp_direct_output=[]\n",
    "for i,idx in enumerate(idxs):\n",
    "    print(\"Testing Image: \", i)\n",
    "    \n",
    "    Img,tar,p_image,p_target = dataset_test.__getitem__(idx) # im,mask_gt\n",
    "    \n",
    "    ticks = np.linspace(0, 1, 6, endpoint=True)\n",
    "\n",
    "    classes_cmap, scale_fig, fonts, scatter_size = defaultScales()\n",
    "\n",
    "    plt.figure(figsize=(15 * scale_fig, 10 * scale_fig))\n",
    "\n",
    "\n",
    "\n",
    "    if p_image.endswith('.png'):\n",
    "        print(p_image)\n",
    "        image = cv2.imread(p_image)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        target = cv2.imread(p_target, cv2.IMREAD_UNCHANGED)\n",
    "        nan_condition = np.count_nonzero(target)\n",
    "        if nan_condition != 0:\n",
    "        # if 1:\n",
    "            number_testing_images = number_testing_images + 1\n",
    "            # add weather augmentation\n",
    "            image_weather = image\n",
    "            target_weather = target\n",
    "            with torch.inference_mode():\n",
    "                model_input = transform_full(image = image_weather)[\"image\"]\n",
    "                model_input = torch.from_numpy(model_input).unsqueeze(0)\n",
    "                model_input -= (0.5 * 255.0)\n",
    "                model_input /= (0.5 * 255.0)\n",
    "                model_input = model_input.to(S_DEVICE)\n",
    "\n",
    "            \n",
    "                logits = model(model_input) # 1,3,512,512\n",
    "                logits = logits[:,0:1,:,:]\n",
    "                prediction = (torch.where(logits > 0.5 , torch.tensor(1).to(S_DEVICE), torch.tensor(0).to(S_DEVICE))).to(torch.float32)\n",
    "                prediction = prediction[0,0].cpu().detach().numpy()\n",
    "                building_mask_float = prediction\n",
    "                \n",
    "                # logits = model(model_input)\n",
    "                # prediction = (torch.where(logits > 0 , torch.tensor(1).to(S_DEVICE), torch.tensor(0).to(S_DEVICE))).to(torch.float32)\n",
    "                # prediction = prediction[0,0].cpu().detach().numpy()\n",
    "                # car_mask_float = prediction\n",
    "            \n",
    "                # print(\"car_mask_float info:\", car_mask_float.shape, car_mask_float.dtype, car_mask_float.max())\n",
    "                \n",
    "            targets = [SemanticSegmentationTarget(building_category, building_mask_float)]\n",
    "                        \n",
    "            # Seg-Grad-CAM (Original)\n",
    "            # print('Running: Seg-Grad-Cam ...')\n",
    "\n",
    "            with GRADCAMEXTENDED(model=model, target_layers=target_layers, use_cuda= False) as cam: # \n",
    "                grayscale_cam_EX = cam(input_tensor=model_input, targets=targets)[0, :]\n",
    "                # print(\"grayscale_cam_EX\", grayscale_cam_EX.shape)\n",
    "                # print(rgb_img.shape)\n",
    "                # print(grayscale_cam_EX.shape)\n",
    "                # seg_grad_cam_original = show_cam_on_image(rgb_img, grayscale_cam_EX, use_rgb=True)\n",
    "                \n",
    "            # Seg-Grad-CAM ++ (Original)\n",
    "            # print('Running: Seg-Grad-Cam++ ...')\n",
    "            with GRADCAMEXTENDED_Plusplus(model=model, target_layers=target_layers, use_cuda=False) as cam:\n",
    "                grayscale_cam_EX_Plusplus = cam(input_tensor=model_input, targets=targets)[0, :]\n",
    "                # Plusplus_seg_grad_cam_original = show_cam_on_image(rgb_img, grayscale_cam_EX_Plusplus, use_rgb=True)\n",
    "                \n",
    "            # plt.imshow(grayscale_cam_EX_Plusplus)\n",
    "            # plt.show()\n",
    "\n",
    "            ###############################################################################################################\n",
    "\n",
    "                                            #UNCOMMENT THE INTEGRATION METHOD YOU WANT TO USE\n",
    "\n",
    "            ###############################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "            ### Ec = Lc*I ###\n",
    "            E_sobol = model_input * list_of_sobol[i]\n",
    "            E_seg_grad_cam_plusPlus = model_input * grayscale_cam_EX_Plusplus\n",
    "\n",
    "            ### Ec= N(Lc)+I ###\n",
    "            # normal_distribution = torch.distributions.normal.Normal(0, 1)\n",
    "            # epsilon = normal_distribution.sample(grayscale_cam_EX.shape).type_as(torch.tensor(grayscale_cam_EX))\n",
    "            # noise = epsilon * (1 - grayscale_cam_EX)\n",
    "            # noise_pp = epsilon * (1 - grayscale_cam_EX_Plusplus)\n",
    "            # E_sobol = model_input + noise\n",
    "            # E_seg_grad_cam_plusPlus = model_input + noise_pp\n",
    "\n",
    "            ### Ec=Lc+I ###\n",
    "            # noise = (1 - list_of_sobol[i])\n",
    "            # noise_pp = (1 - grayscale_cam_EX_Plusplus)\n",
    "            # E_sobol = model_input + noise\n",
    "            # E_seg_grad_cam_plusPlus = model_input + noise_pp\n",
    "\n",
    "            ### Ec = N(Lc)*I ###\n",
    "            # normal_distribution = torch.distributions.normal.Normal(0, 1)\n",
    "            # epsilon = normal_distribution.sample(grayscale_cam_EX.shape).type_as(torch.tensor(grayscale_cam_EX))\n",
    "            # noise = epsilon * (1 - grayscale_cam_EX)\n",
    "            # noise_pp = epsilon * (1 - grayscale_cam_EX_Plusplus)\n",
    "            # E_sobol = model_input * noise\n",
    "            # E_seg_grad_cam_plusPlus = model_input * noise_pp\n",
    "\n",
    "            ### Ec = N(Lc) ###\n",
    "            # normal_distribution = torch.distributions.normal.Normal(0, 1)\n",
    "            # epsilon = normal_distribution.sample(grayscale_cam_EX.shape).type_as(torch.tensor(grayscale_cam_EX))\n",
    "            # noise = epsilon * (1 - grayscale_cam_EX)\n",
    "            # noise_pp = epsilon * (1 - grayscale_cam_EX_Plusplus)\n",
    "            # E_sobol = noise.unsqueeze(0)\n",
    "            # E_seg_grad_cam_plusPlus = noise_pp.unsqueeze(0)\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            #append CAM/CAM++ output\n",
    "            CAM_direct_output.append(grayscale_cam_EX)\n",
    "            CAMpp_direct_output.append(grayscale_cam_EX_Plusplus)\n",
    "            \n",
    "            # Save results...\n",
    "            E_cam = deprocess_image(E_sobol[0].cpu().numpy().transpose((1, 2, 0)))\n",
    "            E_cam_pp = deprocess_image(E_seg_grad_cam_plusPlus[0].cpu().numpy().transpose((1, 2, 0)))\n",
    "\n",
    "            # cam_path = \"./saved_images/E_cam.png\"\n",
    "            # cam_pp_path = \"./saved_images/E_cam_pp.png\"\n",
    "            # plt.imshow(E_cam)\n",
    "            # plt.savefig(cam_path,dpi = 200,facecolor='white', transparent=False,bbox_inches='tight')\n",
    "            # # plt.show()\n",
    "            # # plt.close()\n",
    "            # plt.imshow(E_cam_pp)\n",
    "            # plt.savefig(cam_pp_path,dpi = 200,facecolor='white', transparent=False,bbox_inches='tight')\n",
    "            # # plt.show()\n",
    "            # plt.close()\n",
    "\n",
    "            ### show ecam/ecampp ###\n",
    "            plt.subplot(221)\n",
    "            plt.axis('off')\n",
    "            plt.imshow(E_cam, cmap=None)\n",
    "            plt.title('Seg-Grad-Cam', fontsize=fonts)\n",
    "            \n",
    "            plt.subplot(222)\n",
    "            plt.axis('off')\n",
    "            plt.imshow(E_cam_pp, cmap='jet')\n",
    "            plt.title('Seg-Grad-Cam ++', fontsize=fonts)\n",
    "            plt.show()\n",
    "\n",
    "            # mask_temp = torch.tensor(grayscale_cam_EX > 0.2).to(torch.uint8)\n",
    "            # print(mask_temp.shape, mask_temp.min(), mask_temp.max())\n",
    "            # plt.imshow(mask_temp)\n",
    "            # plt.show()\n",
    "\n",
    "            # mask_temp = torch.tensor(grayscale_cam_EX_Plusplus > 0.2).to(torch.uint8)\n",
    "            # print(mask_temp.shape, mask_temp.min(), mask_temp.max())\n",
    "            # plt.imshow(mask_temp)\n",
    "            # plt.show()\n",
    "\n",
    "            # plt.subplot(221)\n",
    "            # plt.axis('off')\n",
    "            # plt.imshow(E_seg_grad_cam[0].cpu().numpy().transpose((1, 2, 0)),vmin =-2, vmax=+2, cmap=None)\n",
    "            # plt.title('Seg-Grad-Cam', fontsize=fonts)\n",
    "            \n",
    "            # plt.subplot(222)\n",
    "            # plt.axis('off')\n",
    "            # plt.imshow(E_seg_grad_cam_plusPlus[0].cpu().numpy().transpose((1, 2, 0)), cmap='jet')\n",
    "            # plt.title('Seg-Grad-Cam ++', fontsize=fonts)\n",
    "            # plt.show()\n",
    "            \n",
    "            # plt.subplot(223)\n",
    "            # plt.axis('off')\n",
    "            # plt.imshow(E_cam_Noise_Mask, cmap='jet')\n",
    "            # plt.title('Seg-Grad-Cam (Noise Mask)', fontsize=fonts)\n",
    "            \n",
    "            # plt.subplot(224)\n",
    "            # plt.axis('off')\n",
    "            # plt.imshow(E_cam_pp_Noise_Mask, cmap='jet')\n",
    "            # plt.title('Seg-Grad-Cam ++ (Noise Mask)', fontsize=fonts)\n",
    "            \n",
    "            sobol_list.append(E_sobol)\n",
    "            seg_pp_list.append(E_seg_grad_cam_plusPlus)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9d74b2-a15f-482f-af09-c26e460d3844",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "from glob import glob\n",
    "import os\n",
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch.encoders import get_preprocessing_fn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from dataset_cityscapes import *\n",
    "from epoch import *\n",
    "import neptune\n",
    "import pickle\n",
    "from segmentation_models_pytorch import Unet\n",
    "import torch\n",
    "import argparse\n",
    "import os\n",
    "import cv2\n",
    "from segmentation_models_pytorch import Unet\n",
    "from skimage.io import imread,imsave\n",
    "import numpy as np\n",
    "import rasterio as rio\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "\n",
    "from utils import *\n",
    "# from color_map import cm_data\n",
    "from rasterio.features import shapes\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def to_tensor(x, **kwargs):\n",
    "    return x.transpose(2, 0, 1).astype(\"float32\")\n",
    "\n",
    "\n",
    "# ======== CONFIGURATION ======== #\n",
    "S_NAME_ENCODER = \"efficientnet-b4\"\n",
    "S_NAME_WEIGHTS = \"imagenet\"\n",
    "P_DIR_MODEL_NOISE = \"/home/jamada/jupyterlab/eo-xai/whu_noise_training/UNET_EfficientNetB4_CE/Checkpoints-479/model_epoch_0050.pth\"\n",
    "\n",
    "S_DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"CPU\")\n",
    "# S_DEVICE = 'cpu'\n",
    "P_DIR_MODEL_UTIL =\"/home/jamada/UrbanModels/weights_pytorch/tu-tf_efficientnet_b0_Unet_whu_3-classes_40-epochs_TRY001\"\n",
    "\n",
    "# ======== UTILITY ======== #\n",
    "model = Unet(\n",
    "        encoder_name = \"tu-tf_efficientnet_b0\",\n",
    "        encoder_depth= 5,\n",
    "        encoder_weights = None,\n",
    "        decoder_use_batchnorm = True,\n",
    "        decoder_channels = (256, 128, 64, 32, 16),\n",
    "        decoder_attention_type = None,\n",
    "        in_channels= 3,\n",
    "        classes = 3,\n",
    "        activation = 'sigmoid',\n",
    "        aux_params = None,\n",
    "    )\n",
    "\n",
    "utility_model = load_model(model,P_DIR_MODEL_UTIL)\n",
    "\n",
    "# ======== SETUP ======== #\n",
    "# setup model\n",
    "noise_model = torch.load(P_DIR_MODEL_NOISE, map_location=S_DEVICE)  \n",
    "noise_model.eval()\n",
    "\n",
    "# setup input normalization\n",
    "preprocess_input = get_preprocessing_fn(\n",
    "    encoder_name = S_NAME_ENCODER,\n",
    "    pretrained = S_NAME_WEIGHTS,\n",
    ")\n",
    "\n",
    "transform_full = A.Compose([\n",
    "    A.Lambda(name = \"to_tensor\", image = to_tensor),\n",
    "])\n",
    "\n",
    "# setup datasets\n",
    "dataset_test = DataLoaderSegmentation(\n",
    "    image_path = \"/home/jamada/jupyterlab/datasets/WHU/WHU_building/train/A\",\n",
    "    mask_path = \"/home/jamada/jupyterlab/datasets/WHU/WHU_building/train/OUT\",\n",
    "    transform = transform_full,\n",
    "    device = S_DEVICE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb6c458",
   "metadata": {},
   "source": [
    "- Below cells are identincal, the only difference is that each cell save plots png images with names related to the integration method used.\n",
    "- So if you chose the integration method (Lc*I), only run (Lc*I)_not weighted and (Lc*I)_weighted...\n",
    "- should be all merged to one cell, with variable name according to the integration method used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ae2498-aa86-4306-bf2b-bb58c78e6ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(Lc*I)_not weighted\n",
    "\"\"\"\n",
    "(Lc*I)_not weighted\n",
    "Attempt 1 to sweep from 0- to 1 over Dr. abed implementation\n",
    "and calculate the average/2nd raw moment/whim\n",
    "\"\"\"\n",
    "\n",
    "sweep = np.arange(-0.1,1,0.1)\n",
    "\n",
    "\n",
    "\n",
    "for threshold in sweep:\n",
    "    \n",
    "    temp_SLA=[]\n",
    "    temp_SLM=[]\n",
    "    temp_SLA_pp=[]\n",
    "    temp_SLM_pp=[]\n",
    "    \n",
    "    wimp_SLA=0\n",
    "    wimp_SLM=0\n",
    "    \n",
    "\n",
    "    total_selected_average=0\n",
    "    total_selected_moment=0\n",
    "    \n",
    "    total_selected_average_pp=0\n",
    "    total_selected_moment_pp=0\n",
    "    \n",
    "    for i,imgg in enumerate(sobol_list):\n",
    "        B = torch.sigmoid(noise_model(imgg.cuda()))\n",
    "        B=B.cpu()\n",
    "        mask = torch.tensor(CAM_direct_output[i] > threshold).unsqueeze(0).unsqueeze(0)\n",
    "        # simple average\n",
    "        simple_average = torch.mean(B[0][0]).detach()\n",
    "        # simple crude 2nd raw moment \n",
    "        simple_crude_second_moment = np.mean(np.square(B.detach().numpy().flatten()))\n",
    "        # selected average\n",
    "        selected = torch.masked_select(B, mask)    \n",
    "        selected_average = torch.mean(selected).detach()\n",
    "        # selected crude 2nd raw moment \n",
    "        selected_crude_second_moment = np.mean(np.square(selected.detach().numpy()))\n",
    "\n",
    "        # append values to temporary lists\n",
    "        temp_SLA.append(selected_average)\n",
    "        temp_SLM.append(selected_crude_second_moment)\n",
    "\n",
    "    for i,imgg in enumerate(seg_pp_list):\n",
    "        B = torch.sigmoid(noise_model(imgg.cuda()))\n",
    "        B=B.cpu()\n",
    "        mask = torch.tensor(CAMpp_direct_output[i] > threshold).unsqueeze(0).unsqueeze(0)\n",
    "        # simple average \n",
    "        simple_average = torch.mean(B[0][0]).detach()\n",
    "        # simple crude 2nd raw moment\n",
    "        simple_crude_second_moment = np.mean(np.square(B.detach().numpy().flatten()))\n",
    "        # selected  average\n",
    "        selected = torch.masked_select(B, mask)\n",
    "        selected_average = torch.mean(selected).detach()\n",
    "        # selected crude 2nd raw moment  \n",
    "        selected_crude_second_moment = np.mean(np.square(selected.detach().numpy()))\n",
    "\n",
    "        # append values to temporary lists\n",
    "        temp_SLA_pp.append(selected_average)\n",
    "        temp_SLM_pp.append(selected_crude_second_moment)\n",
    "\n",
    "    total_selected_average= np.mean(temp_SLA)\n",
    "    total_selected_moment= np.mean(temp_SLM)\n",
    "    \n",
    "    total_selected_average_pp= np.mean(temp_SLA_pp)\n",
    "    total_selected_moment_pp= np.mean(temp_SLM_pp)\n",
    "\n",
    "\n",
    "    for i_seg, i_segpp in zip(temp_SLA,temp_SLA_pp):\n",
    "        if i_segpp > i_seg:\n",
    "            wimp_SLA = wimp_SLA+1\n",
    "            \n",
    "\n",
    "    for i_seg, i_segpp in zip(temp_SLM,temp_SLM_pp):\n",
    "        if i_segpp > i_seg:\n",
    "            wimp_SLM = wimp_SLM+1\n",
    "\n",
    "    \n",
    "    # plotting grouped bar chart\n",
    "    species = (\"SOBOL\", \"SEG_CAM++\")\n",
    "    total_means = {\n",
    "        'selected average': (round(total_selected_average,3), round(total_selected_average_pp,3)),\n",
    "        'selected moment': (round(total_selected_moment,3), round(total_selected_moment_pp,3)),\n",
    "    }\n",
    "    # print(total_selected_average,total_selected_average_pp)\n",
    "    \n",
    "    \n",
    "    x = np.arange(len(species))  # the label locations\n",
    "    width = 0.25  # the width of the bars\n",
    "    multiplier = 0\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(layout='constrained')\n",
    "    \n",
    "    for attribute, measurement in total_means.items():\n",
    "        offset = width * multiplier\n",
    "        rects = ax.bar(x + offset, measurement, width, label=attribute)\n",
    "        ax.bar_label(rects, padding=3)\n",
    "        multiplier += 1\n",
    "    \n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    ax.set_ylabel('Total Average')\n",
    "    ax.set_title(f\"Unoise Evaluation Metric - Threshold {round(threshold,2)}\")\n",
    "    ax.set_xticks(x + width, species)\n",
    "    ax.legend(loc='upper left', ncols=3)\n",
    "    ax.set_ylim(0, 1)\n",
    "\n",
    "\n",
    "\n",
    "    # Plot the wimp values next to the chart\n",
    "\n",
    "    ax.text(1, 0.95, f\"wimp_SL_A: {wimp_SLA}\")\n",
    "    ax.text(1, 0.9, f\"wimp_SL_M: {wimp_SLM}\")\n",
    "\n",
    "    # save plots\n",
    "    plt.savefig(f\"evaluation metric plots/(Lc*I)_notWeighed_{round(threshold,2)}.png\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f654b9-5312-430b-8e5d-e58c35f9dee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(Lc+I)_not weighted\n",
    "\"\"\"\n",
    "(Lc+I)_not weighted\n",
    "Attempt 1 to sweep from 0- to 1 over Dr. abed implementation\n",
    "and calculate the average/2nd raw moment/whim\n",
    "\"\"\"\n",
    "\n",
    "sweep = np.arange(-0.1,1,0.1)\n",
    "\n",
    "\n",
    "\n",
    "for threshold in sweep:\n",
    "    \n",
    "    temp_SLA=[]\n",
    "    temp_SLM=[]\n",
    "    temp_SLA_pp=[]\n",
    "    temp_SLM_pp=[]\n",
    "    \n",
    "    wimp_SLA=0\n",
    "    wimp_SLM=0\n",
    "    \n",
    "\n",
    "    total_selected_average=0\n",
    "    total_selected_moment=0\n",
    "    \n",
    "    total_selected_average_pp=0\n",
    "    total_selected_moment_pp=0\n",
    "    \n",
    "    for i,imgg in enumerate(sobol_list):\n",
    "        B = torch.sigmoid(noise_model(imgg.cuda()))\n",
    "        B=B.cpu()\n",
    "        mask = torch.tensor(CAM_direct_output[i] > threshold).unsqueeze(0).unsqueeze(0)\n",
    "        # simple average\n",
    "        simple_average = torch.mean(B[0][0]).detach()\n",
    "        # simple crude 2nd raw moment \n",
    "        simple_crude_second_moment = np.mean(np.square(B.detach().numpy().flatten()))\n",
    "        # selected average\n",
    "        selected = torch.masked_select(B, mask)    \n",
    "        selected_average = torch.mean(selected).detach()\n",
    "        # selected crude 2nd raw moment \n",
    "        selected_crude_second_moment = np.mean(np.square(selected.detach().numpy()))\n",
    "\n",
    "        # append values to temporary lists\n",
    "        temp_SLA.append(selected_average)\n",
    "        temp_SLM.append(selected_crude_second_moment)\n",
    "\n",
    "    for i,imgg in enumerate(seg_pp_list):\n",
    "        B = torch.sigmoid(noise_model(imgg.cuda()))\n",
    "        B=B.cpu()\n",
    "        mask = torch.tensor(CAMpp_direct_output[i] > threshold).unsqueeze(0).unsqueeze(0)\n",
    "        # simple average \n",
    "        simple_average = torch.mean(B[0][0]).detach()\n",
    "        # simple crude 2nd raw moment\n",
    "        simple_crude_second_moment = np.mean(np.square(B.detach().numpy().flatten()))\n",
    "        # selected  average\n",
    "        selected = torch.masked_select(B, mask)\n",
    "        selected_average = torch.mean(selected).detach()\n",
    "        # selected crude 2nd raw moment  \n",
    "        selected_crude_second_moment = np.mean(np.square(selected.detach().numpy()))\n",
    "\n",
    "        # append values to temporary lists\n",
    "        temp_SLA_pp.append(selected_average)\n",
    "        temp_SLM_pp.append(selected_crude_second_moment)\n",
    "\n",
    "    total_selected_average= np.mean(temp_SLA)\n",
    "    total_selected_moment= np.mean(temp_SLM)\n",
    "    \n",
    "    total_selected_average_pp= np.mean(temp_SLA_pp)\n",
    "    total_selected_moment_pp= np.mean(temp_SLM_pp)\n",
    "\n",
    "\n",
    "    for i_seg, i_segpp in zip(temp_SLA,temp_SLA_pp):\n",
    "        if i_segpp < i_seg:\n",
    "            wimp_SLA = wimp_SLA+1\n",
    "            \n",
    "\n",
    "    for i_seg, i_segpp in zip(temp_SLM,temp_SLM_pp):\n",
    "        if i_segpp < i_seg:\n",
    "            wimp_SLM = wimp_SLM+1\n",
    "\n",
    "    \n",
    "    # plotting grouped bar chart\n",
    "    species = (\"SEG_CAM\", \"SEG_CAM++\")\n",
    "    total_means = {\n",
    "        'selected average': (round(total_selected_average,3), round(total_selected_average_pp,3)),\n",
    "        'selected moment': (round(total_selected_moment,3), round(total_selected_moment_pp,3)),\n",
    "    }\n",
    "    # print(total_selected_average,total_selected_average_pp)\n",
    "    \n",
    "    \n",
    "    x = np.arange(len(species))  # the label locations\n",
    "    width = 0.25  # the width of the bars\n",
    "    multiplier = 0\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(layout='constrained')\n",
    "    \n",
    "    for attribute, measurement in total_means.items():\n",
    "        offset = width * multiplier\n",
    "        rects = ax.bar(x + offset, measurement, width, label=attribute)\n",
    "        ax.bar_label(rects, padding=3)\n",
    "        multiplier += 1\n",
    "    \n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    ax.set_ylabel('Total Average')\n",
    "    ax.set_title(f\"Unoise Evaluation Metric - Threshold {round(threshold,2)}\")\n",
    "    ax.set_xticks(x + width, species)\n",
    "    ax.legend(loc='upper left', ncols=3)\n",
    "    ax.set_ylim(0, 1)\n",
    "\n",
    "\n",
    "\n",
    "    # Plot the wimp values next to the chart\n",
    "\n",
    "    ax.text(1, 0.95, f\"wimp_SL_A: {wimp_SLA}\")\n",
    "    ax.text(1, 0.9, f\"wimp_SL_M: {wimp_SLM}\")\n",
    "\n",
    "    # save plots\n",
    "    plt.savefig(f\"evaluation metric plots/(Lc+I)_notWeighed_{round(threshold,2)}.png\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c9786e-bf4f-4bf0-a55e-8346021672db",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ~N(Lc)+I_not weighted\n",
    "\"\"\"\n",
    " ~N(Lc)+I_not weighted\n",
    "Attempt 1 to sweep from 0- to 1 over Dr. abed implementation\n",
    "and calculate the average/2nd raw moment/whim\n",
    "\"\"\"\n",
    "\n",
    "sweep = np.arange(-0.1,1,0.1)\n",
    "\n",
    "\n",
    "\n",
    "for threshold in sweep:\n",
    "    \n",
    "    temp_SLA=[]\n",
    "    temp_SLM=[]\n",
    "    temp_SLA_pp=[]\n",
    "    temp_SLM_pp=[]\n",
    "    \n",
    "    wimp_SLA=0\n",
    "    wimp_SLM=0\n",
    "    \n",
    "\n",
    "    total_selected_average=0\n",
    "    total_selected_moment=0\n",
    "    \n",
    "    total_selected_average_pp=0\n",
    "    total_selected_moment_pp=0\n",
    "    \n",
    "    for i,imgg in enumerate(sobol_list):\n",
    "        B = torch.sigmoid(noise_model(imgg.cuda()))\n",
    "        B=B.cpu()\n",
    "        mask = torch.tensor(CAM_direct_output[i] > threshold).unsqueeze(0).unsqueeze(0)\n",
    "        # simple average\n",
    "        simple_average = torch.mean(B[0][0]).detach()\n",
    "        # simple crude 2nd raw moment \n",
    "        simple_crude_second_moment = np.mean(np.square(B.detach().numpy().flatten()))\n",
    "        # selected average\n",
    "        selected = torch.masked_select(B, mask)    \n",
    "        selected_average = torch.mean(selected).detach()\n",
    "        # selected crude 2nd raw moment \n",
    "        selected_crude_second_moment = np.mean(np.square(selected.detach().numpy()))\n",
    "\n",
    "        # append values to temporary lists\n",
    "        temp_SLA.append(selected_average)\n",
    "        temp_SLM.append(selected_crude_second_moment)\n",
    "\n",
    "    for i,imgg in enumerate(seg_pp_list):\n",
    "        B = torch.sigmoid(noise_model(imgg.cuda()))\n",
    "        B=B.cpu()\n",
    "        mask = torch.tensor(CAMpp_direct_output[i] > threshold).unsqueeze(0).unsqueeze(0)\n",
    "        # simple average \n",
    "        simple_average = torch.mean(B[0][0]).detach()\n",
    "        # simple crude 2nd raw moment\n",
    "        simple_crude_second_moment = np.mean(np.square(B.detach().numpy().flatten()))\n",
    "        # selected  average\n",
    "        selected = torch.masked_select(B, mask)\n",
    "        selected_average = torch.mean(selected).detach()\n",
    "        # selected crude 2nd raw moment  \n",
    "        selected_crude_second_moment = np.mean(np.square(selected.detach().numpy()))\n",
    "\n",
    "        # append values to temporary lists\n",
    "        temp_SLA_pp.append(selected_average)\n",
    "        temp_SLM_pp.append(selected_crude_second_moment)\n",
    "\n",
    "    total_selected_average= np.mean(temp_SLA)\n",
    "    total_selected_moment= np.mean(temp_SLM)\n",
    "    \n",
    "    total_selected_average_pp= np.mean(temp_SLA_pp)\n",
    "    total_selected_moment_pp= np.mean(temp_SLM_pp)\n",
    "\n",
    "\n",
    "    for i_seg, i_segpp in zip(temp_SLA,temp_SLA_pp):\n",
    "        if i_segpp < i_seg:\n",
    "            wimp_SLA = wimp_SLA+1\n",
    "            \n",
    "\n",
    "    for i_seg, i_segpp in zip(temp_SLM,temp_SLM_pp):\n",
    "        if i_segpp < i_seg:\n",
    "            wimp_SLM = wimp_SLM+1\n",
    "\n",
    "    \n",
    "    # plotting grouped bar chart\n",
    "    species = (\"SEG_CAM\", \"SEG_CAM++\")\n",
    "    total_means = {\n",
    "        'selected average': (round(total_selected_average,3), round(total_selected_average_pp,3)),\n",
    "        'selected moment': (round(total_selected_moment,3), round(total_selected_moment_pp,3)),\n",
    "    }\n",
    "    \n",
    "    \n",
    "    x = np.arange(len(species))  # the label locations\n",
    "    width = 0.25  # the width of the bars\n",
    "    multiplier = 0\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(layout='constrained')\n",
    "    \n",
    "    for attribute, measurement in total_means.items():\n",
    "        offset = width * multiplier\n",
    "        rects = ax.bar(x + offset, measurement, width, label=attribute)\n",
    "        ax.bar_label(rects, padding=3)\n",
    "        multiplier += 1\n",
    "    \n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    ax.set_ylabel('Total Average')\n",
    "    ax.set_title(f\"Unoise Evaluation Metric - Threshold {round(threshold,2)}\")\n",
    "    ax.set_xticks(x + width, species)\n",
    "    ax.legend(loc='upper left', ncols=3)\n",
    "    ax.set_ylim(0, 1)\n",
    "\n",
    "\n",
    "\n",
    "    # Plot the wimp values next to the chart\n",
    "\n",
    "    ax.text(1, 0.95, f\"wimp_SL_A: {wimp_SLA}\")\n",
    "    ax.text(1, 0.9, f\"wimp_SL_M: {wimp_SLM}\")\n",
    "\n",
    "    # save plots\n",
    "    plt.savefig(f\"evaluation metric plots/N(Lc)+I_notWeighed_{round(threshold,2)}.png\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54761f23-538e-4ba4-bce2-c49f1d803297",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#(Lc*I)_weighted\n",
    "\"\"\"\n",
    "(Lc*I)_weighted\n",
    "Attempt 1 to sweep from 0- to 1 over Dr. abed implementation\n",
    "and calculate the average/2nd raw moment/whim\n",
    "\"\"\"\n",
    "\n",
    "sweep = np.arange(-0.1,1,0.1)\n",
    "\n",
    "\n",
    "\n",
    "for threshold in sweep:\n",
    "    \n",
    "    temp_SLA=[]\n",
    "    temp_SLM=[]\n",
    "    temp_SLA_pp=[]\n",
    "    temp_SLM_pp=[]\n",
    "    \n",
    "    wimp_SLA=0\n",
    "    wimp_SLM=0\n",
    "    \n",
    "\n",
    "    total_selected_average=0\n",
    "    total_selected_moment=0\n",
    "    \n",
    "    total_selected_average_pp=0\n",
    "    total_selected_moment_pp=0\n",
    "    \n",
    "    for i,imgg in enumerate(sobol_list):\n",
    "        B = torch.sigmoid(noise_model(imgg.cuda()))\n",
    "        B=B.cpu()\n",
    "        mask = torch.tensor(CAM_direct_output[i] > threshold).unsqueeze(0).unsqueeze(0)\n",
    "        # simple average\n",
    "        simple_average = torch.mean(B[0][0]).detach()\n",
    "        # simple crude 2nd raw moment \n",
    "        simple_crude_second_moment = np.mean(np.square(B.detach().numpy().flatten()))\n",
    "        # selected average\n",
    "        selected = torch.masked_select(torch.tensor((B.detach().numpy())*CAM_direct_output[i]), mask)    \n",
    "        selected_average = torch.mean(selected).detach()\n",
    "        # selected crude 2nd raw moment \n",
    "        selected_crude_second_moment = np.mean(np.square(selected.detach().numpy()))\n",
    "\n",
    "        # append values to temporary lists\n",
    "        temp_SLA.append(selected_average)\n",
    "        temp_SLM.append(selected_crude_second_moment)\n",
    "\n",
    "    for i,imgg in enumerate(seg_pp_list):\n",
    "        B = torch.sigmoid(noise_model(imgg.cuda()))\n",
    "        B=B.cpu()\n",
    "        mask = torch.tensor(CAMpp_direct_output[i] > threshold).unsqueeze(0).unsqueeze(0)\n",
    "        # simple average \n",
    "        simple_average = torch.mean(B[0][0]).detach()\n",
    "        # simple crude 2nd raw moment\n",
    "        simple_crude_second_moment = np.mean(np.square(B.detach().numpy().flatten()))\n",
    "        # selected  average\n",
    "        selected = torch.masked_select(torch.tensor((B.detach().numpy())*CAMpp_direct_output[i]), mask)\n",
    "        selected_average = torch.mean(selected).detach()\n",
    "        # selected crude 2nd raw moment  \n",
    "        selected_crude_second_moment = np.mean(np.square(selected.detach().numpy()))\n",
    "\n",
    "        # append values to temporary lists\n",
    "        temp_SLA_pp.append(selected_average)\n",
    "        temp_SLM_pp.append(selected_crude_second_moment)\n",
    "\n",
    "    total_selected_average= np.mean(temp_SLA)\n",
    "    total_selected_moment= np.mean(temp_SLM)\n",
    "    \n",
    "    total_selected_average_pp= np.mean(temp_SLA_pp)\n",
    "    total_selected_moment_pp= np.mean(temp_SLM_pp)\n",
    "\n",
    "\n",
    "    for i_seg, i_segpp in zip(temp_SLA,temp_SLA_pp):\n",
    "        if i_segpp < i_seg:\n",
    "            wimp_SLA = wimp_SLA+1\n",
    "            \n",
    "\n",
    "    for i_seg, i_segpp in zip(temp_SLM,temp_SLM_pp):\n",
    "        if i_segpp < i_seg:\n",
    "            wimp_SLM = wimp_SLM+1\n",
    "\n",
    "    \n",
    "    # plotting grouped bar chart\n",
    "    species = (\"SEG_CAM\", \"SEG_CAM++\")\n",
    "    total_means = {\n",
    "        'selected average': (round(total_selected_average,3), round(total_selected_average_pp,3)),\n",
    "        'selected moment': (round(total_selected_moment,3), round(total_selected_moment_pp,3)),\n",
    "    }\n",
    "    \n",
    "    \n",
    "    x = np.arange(len(species))  # the label locations\n",
    "    width = 0.25  # the width of the bars\n",
    "    multiplier = 0\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(layout='constrained')\n",
    "    \n",
    "    for attribute, measurement in total_means.items():\n",
    "        offset = width * multiplier\n",
    "        rects = ax.bar(x + offset, measurement, width, label=attribute)\n",
    "        ax.bar_label(rects, padding=3)\n",
    "        multiplier += 1\n",
    "    \n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    ax.set_ylabel('Total Average')\n",
    "    ax.set_title(f\"Unoise Evaluation Metric - Threshold {round(threshold,2)}\")\n",
    "    ax.set_xticks(x + width, species)\n",
    "    ax.legend(loc='upper left', ncols=3)\n",
    "    ax.set_ylim(0, 1)\n",
    "\n",
    "\n",
    "\n",
    "    # Plot the wimp values next to the chart\n",
    "\n",
    "    ax.text(1, 0.95, f\"wimp_SL_A: {wimp_SLA}\")\n",
    "    ax.text(1, 0.9, f\"wimp_SL_M: {wimp_SLM}\")\n",
    "\n",
    "    # save plots\n",
    "    plt.savefig(f\"evaluation metric plots/(Lc*I)_Weighed_{round(threshold,2)}.png\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3039960c-4932-4bd4-a917-02c82d0fb067",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#(Lc+I)_weighted\n",
    "\"\"\"\n",
    "(Lc+I)_weighted\n",
    "Attempt 1 to sweep from 0- to 1 over Dr. abed implementation\n",
    "and calculate the average/2nd raw moment/whim\n",
    "\"\"\"\n",
    "\n",
    "sweep = np.arange(-0.1,1,0.1)\n",
    "\n",
    "\n",
    "\n",
    "for threshold in sweep:\n",
    "    \n",
    "    temp_SLA=[]\n",
    "    temp_SLM=[]\n",
    "    temp_SLA_pp=[]\n",
    "    temp_SLM_pp=[]\n",
    "    \n",
    "    wimp_SLA=0\n",
    "    wimp_SLM=0\n",
    "    \n",
    "\n",
    "    total_selected_average=0\n",
    "    total_selected_moment=0\n",
    "    \n",
    "    total_selected_average_pp=0\n",
    "    total_selected_moment_pp=0\n",
    "    \n",
    "    for i,imgg in enumerate(sobol_list):\n",
    "        B = torch.sigmoid(noise_model(imgg.cuda()))\n",
    "        B=B.cpu()\n",
    "        mask = torch.tensor(CAM_direct_output[i] > threshold).unsqueeze(0).unsqueeze(0)\n",
    "        # simple average\n",
    "        simple_average = torch.mean(B[0][0]).detach()\n",
    "        # simple crude 2nd raw moment \n",
    "        simple_crude_second_moment = np.mean(np.square(B.detach().numpy().flatten()))\n",
    "        # selected average\n",
    "        selected = torch.masked_select(torch.tensor((B.detach().numpy())*CAM_direct_output[i]), mask)    \n",
    "        selected_average = torch.mean(selected).detach()\n",
    "        # selected crude 2nd raw moment \n",
    "        selected_crude_second_moment = np.mean(np.square(selected.detach().numpy()))\n",
    "\n",
    "        # append values to temporary lists\n",
    "        temp_SLA.append(selected_average)\n",
    "        temp_SLM.append(selected_crude_second_moment)\n",
    "\n",
    "    for i,imgg in enumerate(seg_pp_list):\n",
    "        B = torch.sigmoid(noise_model(imgg.cuda()))\n",
    "        B = B.cpu()\n",
    "        mask = torch.tensor(CAMpp_direct_output[i] > threshold).unsqueeze(0).unsqueeze(0)\n",
    "        # simple average \n",
    "        simple_average = torch.mean(B[0][0]).detach()\n",
    "        # simple crude 2nd raw moment\n",
    "        simple_crude_second_moment = np.mean(np.square(B.detach().numpy().flatten()))\n",
    "        # selected  average\n",
    "        selected = torch.masked_select(torch.tensor((B.detach().numpy())*CAMpp_direct_output[i]), mask)\n",
    "        selected_average = torch.mean(selected).detach()\n",
    "        # selected crude 2nd raw moment  \n",
    "        selected_crude_second_moment = np.mean(np.square(selected.detach().numpy()))\n",
    "\n",
    "        # append values to temporary lists\n",
    "        temp_SLA_pp.append(selected_average)\n",
    "        temp_SLM_pp.append(selected_crude_second_moment)\n",
    "\n",
    "    total_selected_average= np.mean(temp_SLA)\n",
    "    total_selected_moment= np.mean(temp_SLM)\n",
    "    \n",
    "    total_selected_average_pp= np.mean(temp_SLA_pp)\n",
    "    total_selected_moment_pp= np.mean(temp_SLM_pp)\n",
    "\n",
    "\n",
    "    for i_seg, i_segpp in zip(temp_SLA,temp_SLA_pp):\n",
    "        if i_segpp < i_seg:\n",
    "            wimp_SLA = wimp_SLA+1\n",
    "            \n",
    "\n",
    "    for i_seg, i_segpp in zip(temp_SLM,temp_SLM_pp):\n",
    "        if i_segpp < i_seg:\n",
    "            wimp_SLM = wimp_SLM+1\n",
    "\n",
    "    \n",
    "    # plotting grouped bar chart\n",
    "    species = (\"SEG_CAM\", \"SEG_CAM++\")\n",
    "    total_means = {\n",
    "        'selected average': (round(total_selected_average,3), round(total_selected_average_pp,3)),\n",
    "        'selected moment': (round(total_selected_moment,3), round(total_selected_moment_pp,3)),\n",
    "    }\n",
    "    \n",
    "    \n",
    "    x = np.arange(len(species))  # the label locations\n",
    "    width = 0.25  # the width of the bars\n",
    "    multiplier = 0\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(layout='constrained')\n",
    "    \n",
    "    for attribute, measurement in total_means.items():\n",
    "        offset = width * multiplier\n",
    "        rects = ax.bar(x + offset, measurement, width, label=attribute)\n",
    "        ax.bar_label(rects, padding=3)\n",
    "        multiplier += 1\n",
    "    \n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    ax.set_ylabel('Total Average')\n",
    "    ax.set_title(f\"Unoise Evaluation Metric - Threshold {round(threshold,2)}\")\n",
    "    ax.set_xticks(x + width, species)\n",
    "    ax.legend(loc='upper left', ncols=3)\n",
    "    ax.set_ylim(0, 1)\n",
    "\n",
    "\n",
    "\n",
    "    # Plot the wimp values next to the chart\n",
    "\n",
    "    ax.text(1, 0.95, f\"wimp_SL_A: {wimp_SLA}\")\n",
    "    ax.text(1, 0.9, f\"wimp_SL_M: {wimp_SLM}\")\n",
    "\n",
    "    # save plots\n",
    "    plt.savefig(f\"evaluation metric plots/(Lc+I)_Weighed_{round(threshold,2)}.png\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d141110e-1db5-4bff-90a9-6c6c1da71b9a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ~N(Lc)+I_weighted\n",
    "\"\"\"\n",
    "~N(Lc)+I_weighted\n",
    "Attempt 1 to sweep from 0- to 1 over Dr. abed implementation\n",
    "and calculate the average/2nd raw moment/whim\n",
    "\"\"\"\n",
    "\n",
    "sweep = np.arange(-0.1,1,0.1)\n",
    "\n",
    "\n",
    "\n",
    "for threshold in sweep:\n",
    "    \n",
    "    temp_SLA=[]\n",
    "    temp_SLM=[]\n",
    "    temp_SLA_pp=[]\n",
    "    temp_SLM_pp=[]\n",
    "    \n",
    "    wimp_SLA=0\n",
    "    wimp_SLM=0\n",
    "    \n",
    "\n",
    "    total_selected_average=0\n",
    "    total_selected_moment=0\n",
    "    \n",
    "    total_selected_average_pp=0\n",
    "    total_selected_moment_pp=0\n",
    "    \n",
    "    for i,imgg in enumerate(sobol_list):\n",
    "        B = torch.sigmoid(noise_model(imgg.cuda()))\n",
    "        B=B.cpu()\n",
    "        mask = torch.tensor(CAM_direct_output[i] > threshold).unsqueeze(0).unsqueeze(0)\n",
    "        # simple average\n",
    "        simple_average = torch.mean(B[0][0]).detach()\n",
    "        # simple crude 2nd raw moment \n",
    "        simple_crude_second_moment = np.mean(np.square(B.detach().numpy().flatten()))\n",
    "        # selected average\n",
    "        selected = torch.masked_select(torch.tensor((B.detach().numpy())*CAM_direct_output[i]), mask)    \n",
    "        selected_average = torch.mean(selected).detach()\n",
    "        # selected crude 2nd raw moment \n",
    "        selected_crude_second_moment = np.mean(np.square(selected.detach().numpy()))\n",
    "\n",
    "        # append values to temporary lists\n",
    "        temp_SLA.append(selected_average)\n",
    "        temp_SLM.append(selected_crude_second_moment)\n",
    "\n",
    "    for i,imgg in enumerate(seg_pp_list):\n",
    "        B = torch.sigmoid(noise_model(imgg.cuda()))\n",
    "        B=B.cpu()\n",
    "        mask = torch.tensor(CAMpp_direct_output[i] > threshold).unsqueeze(0).unsqueeze(0)\n",
    "        # simple average \n",
    "        simple_average = torch.mean(B[0][0]).detach()\n",
    "        # simple crude 2nd raw moment\n",
    "        simple_crude_second_moment = np.mean(np.square(B.detach().numpy().flatten()))\n",
    "        # selected  average\n",
    "        selected = torch.masked_select(torch.tensor((B.detach().numpy())*CAMpp_direct_output[i]), mask)\n",
    "        selected_average = torch.mean(selected).detach()\n",
    "        # selected crude 2nd raw moment  \n",
    "        selected_crude_second_moment = np.mean(np.square(selected.detach().numpy()))\n",
    "\n",
    "        # append values to temporary lists\n",
    "        temp_SLA_pp.append(selected_average)\n",
    "        temp_SLM_pp.append(selected_crude_second_moment)\n",
    "\n",
    "    total_selected_average= np.mean(temp_SLA)\n",
    "    total_selected_moment= np.mean(temp_SLM)\n",
    "    \n",
    "    total_selected_average_pp= np.mean(temp_SLA_pp)\n",
    "    total_selected_moment_pp= np.mean(temp_SLM_pp)\n",
    "\n",
    "\n",
    "    for i_seg, i_segpp in zip(temp_SLA,temp_SLA_pp):\n",
    "        if i_segpp < i_seg:\n",
    "            wimp_SLA = wimp_SLA+1\n",
    "            \n",
    "\n",
    "    for i_seg, i_segpp in zip(temp_SLM,temp_SLM_pp):\n",
    "        if i_segpp < i_seg:\n",
    "            wimp_SLM = wimp_SLM+1\n",
    "\n",
    "    \n",
    "    # plotting grouped bar chart\n",
    "    species = (\"SEG_CAM\", \"SEG_CAM++\")\n",
    "    total_means = {\n",
    "        'selected average': (round(total_selected_average,3), round(total_selected_average_pp,3)),\n",
    "        'selected moment': (round(total_selected_moment,3), round(total_selected_moment_pp,3)),\n",
    "    }\n",
    "    \n",
    "    \n",
    "    x = np.arange(len(species))  # the label locations\n",
    "    width = 0.25  # the width of the bars\n",
    "    multiplier = 0\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(layout='constrained')\n",
    "    \n",
    "    for attribute, measurement in total_means.items():\n",
    "        offset = width * multiplier\n",
    "        rects = ax.bar(x + offset, measurement, width, label=attribute)\n",
    "        ax.bar_label(rects, padding=3)\n",
    "        multiplier += 1\n",
    "    \n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    ax.set_ylabel('Total Average')\n",
    "    ax.set_title(f\"Unoise Evaluation Metric - Threshold {round(threshold,2)}\")\n",
    "    ax.set_xticks(x + width, species)\n",
    "    ax.legend(loc='upper left', ncols=3)\n",
    "    ax.set_ylim(0, 1)\n",
    "\n",
    "\n",
    "\n",
    "    # Plot the wimp values next to the chart\n",
    "\n",
    "    ax.text(1, 0.95, f\"wimp_SL_A: {wimp_SLA}\")\n",
    "    ax.text(1, 0.9, f\"wimp_SL_M: {wimp_SLM}\")\n",
    "\n",
    "    # save plots\n",
    "    plt.savefig(f\"evaluation metric plots/N(Lc)+I_Weighed_{round(threshold,2)}.png\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005d534a-7bed-4b6d-96ba-abb4b98b650f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ~N(Lc)*I_not weighted\n",
    "\"\"\"\n",
    " ~N(Lc)*I_not weighted\n",
    "Attempt 1 to sweep from 0- to 1 over Dr. abed implementation\n",
    "and calculate the average/2nd raw moment/whim\n",
    "\"\"\"\n",
    "\n",
    "sweep = np.arange(-0.1,1,0.1)\n",
    "\n",
    "\n",
    "\n",
    "for threshold in sweep:\n",
    "    \n",
    "    temp_SLA=[]\n",
    "    temp_SLM=[]\n",
    "    temp_SLA_pp=[]\n",
    "    temp_SLM_pp=[]\n",
    "    \n",
    "    wimp_SLA=0\n",
    "    wimp_SLM=0\n",
    "    \n",
    "\n",
    "    total_selected_average=0\n",
    "    total_selected_moment=0\n",
    "    \n",
    "    total_selected_average_pp=0\n",
    "    total_selected_moment_pp=0\n",
    "    \n",
    "    for i,imgg in enumerate(sobol_list):\n",
    "        B = torch.sigmoid(noise_model(imgg.cuda()))\n",
    "        B=B.cpu()\n",
    "        mask = torch.tensor(CAM_direct_output[i] > threshold).unsqueeze(0).unsqueeze(0)\n",
    "        # simple average\n",
    "        simple_average = torch.mean(B[0][0]).detach()\n",
    "        # simple crude 2nd raw moment \n",
    "        simple_crude_second_moment = np.mean(np.square(B.detach().numpy().flatten()))\n",
    "        # selected average\n",
    "        selected = torch.masked_select(B, mask)    \n",
    "        selected_average = torch.mean(selected).detach()\n",
    "        # selected crude 2nd raw moment \n",
    "        selected_crude_second_moment = np.mean(np.square(selected.detach().numpy()))\n",
    "\n",
    "        # append values to temporary lists\n",
    "        temp_SLA.append(selected_average)\n",
    "        temp_SLM.append(selected_crude_second_moment)\n",
    "\n",
    "    for i,imgg in enumerate(seg_pp_list):\n",
    "        B = torch.sigmoid(noise_model(imgg.cuda()))\n",
    "        B=B.cpu()\n",
    "        mask = torch.tensor(CAMpp_direct_output[i] > threshold).unsqueeze(0).unsqueeze(0)\n",
    "        # simple average \n",
    "        simple_average = torch.mean(B[0][0]).detach()\n",
    "        # simple crude 2nd raw moment\n",
    "        simple_crude_second_moment = np.mean(np.square(B.detach().numpy().flatten()))\n",
    "        # selected  average\n",
    "        selected = torch.masked_select(B, mask)\n",
    "        selected_average = torch.mean(selected).detach()\n",
    "        # selected crude 2nd raw moment  \n",
    "        selected_crude_second_moment = np.mean(np.square(selected.detach().numpy()))\n",
    "\n",
    "        # append values to temporary lists\n",
    "        temp_SLA_pp.append(selected_average)\n",
    "        temp_SLM_pp.append(selected_crude_second_moment)\n",
    "\n",
    "    total_selected_average= np.mean(temp_SLA)\n",
    "    total_selected_moment= np.mean(temp_SLM)\n",
    "    \n",
    "    total_selected_average_pp= np.mean(temp_SLA_pp)\n",
    "    total_selected_moment_pp= np.mean(temp_SLM_pp)\n",
    "\n",
    "\n",
    "    for i_seg, i_segpp in zip(temp_SLA,temp_SLA_pp):\n",
    "        if i_segpp < i_seg:\n",
    "            wimp_SLA = wimp_SLA+1\n",
    "            \n",
    "\n",
    "    for i_seg, i_segpp in zip(temp_SLM,temp_SLM_pp):\n",
    "        if i_segpp < i_seg:\n",
    "            wimp_SLM = wimp_SLM+1\n",
    "\n",
    "    \n",
    "    # plotting grouped bar chart\n",
    "    species = (\"SEG_CAM\", \"SEG_CAM++\")\n",
    "    total_means = {\n",
    "        'selected average': (round(total_selected_average,3), round(total_selected_average_pp,3)),\n",
    "        'selected moment': (round(total_selected_moment,3), round(total_selected_moment_pp,3)),\n",
    "    }\n",
    "    \n",
    "    \n",
    "    x = np.arange(len(species))  # the label locations\n",
    "    width = 0.25  # the width of the bars\n",
    "    multiplier = 0\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(layout='constrained')\n",
    "    \n",
    "    for attribute, measurement in total_means.items():\n",
    "        offset = width * multiplier\n",
    "        rects = ax.bar(x + offset, measurement, width, label=attribute)\n",
    "        ax.bar_label(rects, padding=3)\n",
    "        multiplier += 1\n",
    "    \n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    ax.set_ylabel('Total Average')\n",
    "    ax.set_title(f\"Unoise Evaluation Metric - Threshold {round(threshold,2)}\")\n",
    "    ax.set_xticks(x + width, species)\n",
    "    ax.legend(loc='upper left', ncols=3)\n",
    "    ax.set_ylim(0, 1)\n",
    "\n",
    "\n",
    "\n",
    "    # Plot the wimp values next to the chart\n",
    "\n",
    "    ax.text(1, 0.95, f\"wimp_SL_A: {wimp_SLA}\")\n",
    "    ax.text(1, 0.9, f\"wimp_SL_M: {wimp_SLM}\")\n",
    "\n",
    "    # save plots\n",
    "    plt.savefig(f\"evaluation metric plots/N(Lc)*I_notWeighed_{round(threshold,2)}.png\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775992b6-f960-4145-98b9-664f43bf12c3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ~N(Lc)*I_weighted\n",
    "\"\"\"\n",
    "~N(Lc)*I_weighted\n",
    "Attempt 1 to sweep from 0- to 1 over Dr. abed implementation\n",
    "and calculate the average/2nd raw moment/whim\n",
    "\"\"\"\n",
    "\n",
    "sweep = np.arange(-0.1,1,0.1)\n",
    "\n",
    "\n",
    "\n",
    "for threshold in sweep:\n",
    "    \n",
    "    temp_SLA=[]\n",
    "    temp_SLM=[]\n",
    "    temp_SLA_pp=[]\n",
    "    temp_SLM_pp=[]\n",
    "    \n",
    "    wimp_SLA=0\n",
    "    wimp_SLM=0\n",
    "    \n",
    "\n",
    "    total_selected_average=0\n",
    "    total_selected_moment=0\n",
    "    \n",
    "    total_selected_average_pp=0\n",
    "    total_selected_moment_pp=0\n",
    "    \n",
    "    for i,imgg in enumerate(sobol_list):\n",
    "        B = torch.sigmoid(noise_model(imgg.cuda()))\n",
    "        B=B.cpu()\n",
    "        mask = torch.tensor(CAM_direct_output[i] > threshold).unsqueeze(0).unsqueeze(0)\n",
    "        # simple average\n",
    "        simple_average = torch.mean(B[0][0]).detach()\n",
    "        # simple crude 2nd raw moment \n",
    "        simple_crude_second_moment = np.mean(np.square(B.detach().numpy().flatten()))\n",
    "        # selected average\n",
    "        selected = torch.masked_select(torch.tensor((B.detach().numpy())*CAM_direct_output[i]), mask)    \n",
    "        selected_average = torch.mean(selected).detach()\n",
    "        # selected crude 2nd raw moment \n",
    "        selected_crude_second_moment = np.mean(np.square(selected.detach().numpy()))\n",
    "\n",
    "        # append values to temporary lists\n",
    "        temp_SLA.append(selected_average)\n",
    "        temp_SLM.append(selected_crude_second_moment)\n",
    "\n",
    "    for i,imgg in enumerate(seg_pp_list):\n",
    "        B = torch.sigmoid(noise_model(imgg.cuda()))\n",
    "        B=B.cpu()\n",
    "        mask = torch.tensor(CAMpp_direct_output[i] > threshold).unsqueeze(0).unsqueeze(0)\n",
    "        # simple average \n",
    "        simple_average = torch.mean(B[0][0]).detach()\n",
    "        # simple crude 2nd raw moment\n",
    "        simple_crude_second_moment = np.mean(np.square(B.detach().numpy().flatten()))\n",
    "        # selected  average\n",
    "        selected = torch.masked_select(torch.tensor((B.detach().numpy())*CAMpp_direct_output[i]), mask)\n",
    "        selected_average = torch.mean(selected).detach()\n",
    "        # selected crude 2nd raw moment  \n",
    "        selected_crude_second_moment = np.mean(np.square(selected.detach().numpy()))\n",
    "\n",
    "        # append values to temporary lists\n",
    "        temp_SLA_pp.append(selected_average)\n",
    "        temp_SLM_pp.append(selected_crude_second_moment)\n",
    "\n",
    "    total_selected_average= np.mean(temp_SLA)\n",
    "    total_selected_moment= np.mean(temp_SLM)\n",
    "    \n",
    "    total_selected_average_pp= np.mean(temp_SLA_pp)\n",
    "    total_selected_moment_pp= np.mean(temp_SLM_pp)\n",
    "\n",
    "\n",
    "    for i_seg, i_segpp in zip(temp_SLA,temp_SLA_pp):\n",
    "        if i_segpp < i_seg:\n",
    "            wimp_SLA = wimp_SLA+1\n",
    "            \n",
    "\n",
    "    for i_seg, i_segpp in zip(temp_SLM,temp_SLM_pp):\n",
    "        if i_segpp < i_seg:\n",
    "            wimp_SLM = wimp_SLM+1\n",
    "\n",
    "    \n",
    "    # plotting grouped bar chart\n",
    "    species = (\"SEG_CAM\", \"SEG_CAM++\")\n",
    "    total_means = {\n",
    "        'selected average': (round(total_selected_average,3), round(total_selected_average_pp,3)),\n",
    "        'selected moment': (round(total_selected_moment,3), round(total_selected_moment_pp,3)),\n",
    "    }\n",
    "    \n",
    "    \n",
    "    x = np.arange(len(species))  # the label locations\n",
    "    width = 0.25  # the width of the bars\n",
    "    multiplier = 0\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(layout='constrained')\n",
    "    \n",
    "    for attribute, measurement in total_means.items():\n",
    "        offset = width * multiplier\n",
    "        rects = ax.bar(x + offset, measurement, width, label=attribute)\n",
    "        ax.bar_label(rects, padding=3)\n",
    "        multiplier += 1\n",
    "    \n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    ax.set_ylabel('Total Average')\n",
    "    ax.set_title(f\"Unoise Evaluation Metric - Threshold {round(threshold,2)}\")\n",
    "    ax.set_xticks(x + width, species)\n",
    "    ax.legend(loc='upper left', ncols=3)\n",
    "    ax.set_ylim(0, 1)\n",
    "\n",
    "\n",
    "\n",
    "    # Plot the wimp values next to the chart\n",
    "\n",
    "    ax.text(1, 0.95, f\"wimp_SL_A: {wimp_SLA}\")\n",
    "    ax.text(1, 0.9, f\"wimp_SL_M: {wimp_SLM}\")\n",
    "\n",
    "    # save plots\n",
    "    plt.savefig(f\"evaluation metric plots/N(Lc)*I_Weighed_{round(threshold,2)}.png\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542055ba-cb8f-410c-8cba-480a122d9e2d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # ~N(Lc)_not weighted\n",
    "# \"\"\"\n",
    "#  ~N(Lc)+I_not weighted\n",
    "# Attempt 1 to sweep from 0- to 1 over Dr. abed implementation\n",
    "# and calculate the average/2nd raw moment/whim\n",
    "# \"\"\"\n",
    "\n",
    "# sweep = np.arange(-0.1,1,0.1)\n",
    "\n",
    "\n",
    "\n",
    "# for threshold in sweep:\n",
    "    \n",
    "#     temp_SLA=[]\n",
    "#     temp_SLM=[]\n",
    "#     temp_SLA_pp=[]\n",
    "#     temp_SLM_pp=[]\n",
    "    \n",
    "#     wimp_SLA=0\n",
    "#     wimp_SLM=0\n",
    "    \n",
    "\n",
    "#     total_selected_average=0\n",
    "#     total_selected_moment=0\n",
    "    \n",
    "#     total_selected_average_pp=0\n",
    "#     total_selected_moment_pp=0\n",
    "    \n",
    "#     for i,imgg in enumerate(sobol_list):\n",
    "#         B = torch.sigmoid(noise_model(imgg))\n",
    "#         ##temporary ##\n",
    "#         logits = -noise_model(imgg)\n",
    "#         heatmap = logits[0,0]\n",
    "#         heatmap = torch.relu(heatmap) / heatmap.max()\n",
    "#         heatmap = heatmap.cpu().detach().numpy()\n",
    "#         heatmap = np.uint8(255 * heatmap)\n",
    "#         heatmap = cv2.applyColorMap(heatmap,  cv2.COLORMAP_JET)\n",
    "#         plt.imshow(heatmap)\n",
    "#         plt.show()\n",
    "#         ##########################\n",
    "#         mask = torch.tensor(CAM_direct_output[i] > threshold).unsqueeze(0).unsqueeze(0)\n",
    "#         # simple average\n",
    "#         simple_average = torch.mean(B[0][0]).detach()\n",
    "#         # simple crude 2nd raw moment \n",
    "#         simple_crude_second_moment = np.mean(np.square(B.detach().numpy().flatten()))\n",
    "#         # selected average\n",
    "#         selected = torch.masked_select(B, mask)    \n",
    "#         selected_average = torch.mean(selected).detach()\n",
    "#         # selected crude 2nd raw moment \n",
    "#         selected_crude_second_moment = np.mean(np.square(selected.detach().numpy()))\n",
    "\n",
    "#         # append values to temporary lists\n",
    "#         temp_SLA.append(selected_average)\n",
    "#         temp_SLM.append(selected_crude_second_moment)\n",
    "\n",
    "#     for i,imgg in enumerate(seg_pp_list):\n",
    "#         B = torch.sigmoid(noise_model(imgg))\n",
    "#         ##temporary ##\n",
    "#         logits = -noise_model(imgg)\n",
    "#         heatmap = logits[0,0]\n",
    "#         heatmap = torch.relu(heatmap) / heatmap.max()\n",
    "#         heatmap = heatmap.cpu().detach().numpy()\n",
    "#         heatmap = np.uint8(255 * heatmap)\n",
    "#         heatmap = cv2.applyColorMap(heatmap,  cv2.COLORMAP_JET)\n",
    "#         plt.imshow(heatmap)\n",
    "#         plt.show()\n",
    "#         ##########################\n",
    "#         mask = torch.tensor(CAMpp_direct_output[i] > threshold).unsqueeze(0).unsqueeze(0)\n",
    "#         # simple average \n",
    "#         simple_average = torch.mean(B[0][0]).detach()\n",
    "#         # simple crude 2nd raw moment\n",
    "#         simple_crude_second_moment = np.mean(np.square(B.detach().numpy().flatten()))\n",
    "#         # selected  average\n",
    "#         selected = torch.masked_select(B, mask)\n",
    "#         selected_average = torch.mean(selected).detach()\n",
    "#         # selected crude 2nd raw moment  \n",
    "#         selected_crude_second_moment = np.mean(np.square(selected.detach().numpy()))\n",
    "\n",
    "#         # append values to temporary lists\n",
    "#         temp_SLA_pp.append(selected_average)\n",
    "#         temp_SLM_pp.append(selected_crude_second_moment)\n",
    "\n",
    "#     total_selected_average= np.mean(temp_SLA)\n",
    "#     total_selected_moment= np.mean(temp_SLM)\n",
    "    \n",
    "#     total_selected_average_pp= np.mean(temp_SLA_pp)\n",
    "#     total_selected_moment_pp= np.mean(temp_SLM_pp)\n",
    "\n",
    "\n",
    "#     for i_seg, i_segpp in zip(temp_SLA,temp_SLA_pp):\n",
    "#         if i_segpp < i_seg:\n",
    "#             wimp_SLA = wimp_SLA+1\n",
    "            \n",
    "\n",
    "#     for i_seg, i_segpp in zip(temp_SLM,temp_SLM_pp):\n",
    "#         if i_segpp < i_seg:\n",
    "#             wimp_SLM = wimp_SLM+1\n",
    "\n",
    "    \n",
    "#     # plotting grouped bar chart\n",
    "#     species = (\"SEG_CAM\", \"SEG_CAM++\")\n",
    "#     total_means = {\n",
    "#         'selected average': (round(total_selected_average,3), round(total_selected_average_pp,3)),\n",
    "#         'selected moment': (round(total_selected_moment,3), round(total_selected_moment_pp,3)),\n",
    "#     }\n",
    "    \n",
    "    \n",
    "#     x = np.arange(len(species))  # the label locations\n",
    "#     width = 0.25  # the width of the bars\n",
    "#     multiplier = 0\n",
    "\n",
    "\n",
    "#     fig, ax = plt.subplots(layout='constrained')\n",
    "    \n",
    "#     for attribute, measurement in total_means.items():\n",
    "#         offset = width * multiplier\n",
    "#         rects = ax.bar(x + offset, measurement, width, label=attribute)\n",
    "#         ax.bar_label(rects, padding=3)\n",
    "#         multiplier += 1\n",
    "    \n",
    "#     # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "#     ax.set_ylabel('Total Average')\n",
    "#     ax.set_title(f\"Unoise Evaluation Metric - Threshold {round(threshold,2)}\")\n",
    "#     ax.set_xticks(x + width, species)\n",
    "#     ax.legend(loc='upper left', ncols=3)\n",
    "#     ax.set_ylim(0, 1)\n",
    "\n",
    "\n",
    "\n",
    "#     # Plot the wimp values next to the chart\n",
    "\n",
    "#     ax.text(1, 0.95, f\"wimp_SL_A: {wimp_SLA}\")\n",
    "#     ax.text(1, 0.9, f\"wimp_SL_M: {wimp_SLM}\")\n",
    "\n",
    "#     # save plots\n",
    "#     plt.savefig(f\"evaluation metric plots/N(Lc)_notWeighed_{round(threshold,2)}.png\")\n",
    "    \n",
    "#     plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7947f261-0435-48af-bd0a-3b88244deecb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # ~N(Lc)_weighted\n",
    "# \"\"\"\n",
    "# ~N(Lc)+I_weighted\n",
    "# Attempt 1 to sweep from 0- to 1 over Dr. abed implementation\n",
    "# and calculate the average/2nd raw moment/whim\n",
    "# \"\"\"\n",
    "\n",
    "# sweep = np.arange(-0.1,1,0.1)\n",
    "\n",
    "\n",
    "\n",
    "# for threshold in sweep:\n",
    "    \n",
    "#     temp_SLA=[]\n",
    "#     temp_SLM=[]\n",
    "#     temp_SLA_pp=[]\n",
    "#     temp_SLM_pp=[]\n",
    "    \n",
    "#     wimp_SLA=0\n",
    "#     wimp_SLM=0\n",
    "    \n",
    "\n",
    "#     total_selected_average=0\n",
    "#     total_selected_moment=0\n",
    "    \n",
    "#     total_selected_average_pp=0\n",
    "#     total_selected_moment_pp=0\n",
    "    \n",
    "#     for i,imgg in enumerate(sobol_list):\n",
    "#         B = torch.sigmoid(noise_model(imgg))\n",
    "#         mask = torch.tensor(CAM_direct_output[i] > threshold).unsqueeze(0).unsqueeze(0)\n",
    "#         # simple average\n",
    "#         simple_average = torch.mean(B[0][0]).detach()\n",
    "#         # simple crude 2nd raw moment \n",
    "#         simple_crude_second_moment = np.mean(np.square(B.detach().numpy().flatten()))\n",
    "#         # selected average\n",
    "#         selected = torch.masked_select(torch.tensor((B.detach().numpy())*CAM_direct_output[i]), mask)    \n",
    "#         selected_average = torch.mean(selected).detach()\n",
    "#         # selected crude 2nd raw moment \n",
    "#         selected_crude_second_moment = np.mean(np.square(selected.detach().numpy()))\n",
    "\n",
    "#         # append values to temporary lists\n",
    "#         temp_SLA.append(selected_average)\n",
    "#         temp_SLM.append(selected_crude_second_moment)\n",
    "\n",
    "#     for i,imgg in enumerate(seg_pp_list):\n",
    "#         B = torch.sigmoid(noise_model(imgg))\n",
    "#         mask = torch.tensor(CAMpp_direct_output[i] > threshold).unsqueeze(0).unsqueeze(0)\n",
    "#         # simple average \n",
    "#         simple_average = torch.mean(B[0][0]).detach()\n",
    "#         # simple crude 2nd raw moment\n",
    "#         simple_crude_second_moment = np.mean(np.square(B.detach().numpy().flatten()))\n",
    "#         # selected  average\n",
    "#         selected = torch.masked_select(torch.tensor((B.detach().numpy())*CAMpp_direct_output[i]), mask)\n",
    "#         selected_average = torch.mean(selected).detach()\n",
    "#         # selected crude 2nd raw moment  \n",
    "#         selected_crude_second_moment = np.mean(np.square(selected.detach().numpy()))\n",
    "\n",
    "#         # append values to temporary lists\n",
    "#         temp_SLA_pp.append(selected_average)\n",
    "#         temp_SLM_pp.append(selected_crude_second_moment)\n",
    "\n",
    "#     total_selected_average= np.mean(temp_SLA)\n",
    "#     total_selected_moment= np.mean(temp_SLM)\n",
    "    \n",
    "#     total_selected_average_pp= np.mean(temp_SLA_pp)\n",
    "#     total_selected_moment_pp= np.mean(temp_SLM_pp)\n",
    "\n",
    "\n",
    "#     for i_seg, i_segpp in zip(temp_SLA,temp_SLA_pp):\n",
    "#         if i_segpp < i_seg:\n",
    "#             wimp_SLA = wimp_SLA+1\n",
    "            \n",
    "\n",
    "#     for i_seg, i_segpp in zip(temp_SLM,temp_SLM_pp):\n",
    "#         if i_segpp < i_seg:\n",
    "#             wimp_SLM = wimp_SLM+1\n",
    "\n",
    "    \n",
    "#     # plotting grouped bar chart\n",
    "#     species = (\"SEG_CAM\", \"SEG_CAM++\")\n",
    "#     total_means = {\n",
    "#         'selected average': (round(total_selected_average,3), round(total_selected_average_pp,3)),\n",
    "#         'selected moment': (round(total_selected_moment,3), round(total_selected_moment_pp,3)),\n",
    "#     }\n",
    "    \n",
    "    \n",
    "#     x = np.arange(len(species))  # the label locations\n",
    "#     width = 0.25  # the width of the bars\n",
    "#     multiplier = 0\n",
    "\n",
    "\n",
    "#     fig, ax = plt.subplots(layout='constrained')\n",
    "    \n",
    "#     for attribute, measurement in total_means.items():\n",
    "#         offset = width * multiplier\n",
    "#         rects = ax.bar(x + offset, measurement, width, label=attribute)\n",
    "#         ax.bar_label(rects, padding=3)\n",
    "#         multiplier += 1\n",
    "    \n",
    "#     # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "#     ax.set_ylabel('Total Average')\n",
    "#     ax.set_title(f\"Unoise Evaluation Metric - Threshold {round(threshold,2)}\")\n",
    "#     ax.set_xticks(x + width, species)\n",
    "#     ax.legend(loc='upper left', ncols=3)\n",
    "#     ax.set_ylim(0, 1)\n",
    "\n",
    "\n",
    "\n",
    "#     # Plot the wimp values next to the chart\n",
    "\n",
    "#     ax.text(1, 0.95, f\"wimp_SL_A: {wimp_SLA}\")\n",
    "#     ax.text(1, 0.9, f\"wimp_SL_M: {wimp_SLM}\")\n",
    "\n",
    "#     # save plots\n",
    "#     plt.savefig(f\"evaluation metric plots/N(Lc)_Weighed_{round(threshold,2)}.png\")\n",
    "    \n",
    "#     plt.show()\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
